import streamlit as st
import pandas as pd
import os
import logging
import re
from difflib import SequenceMatcher
import jieba
from concurrent.futures import ThreadPoolExecutor, as_completed
import openpyxl
from openpyxl.styles import PatternFill
import numbers
from io import BytesIO
import base64
import sys


# ============================
# åˆå§‹åŒ–è®¾ç½®
# ============================
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.info("å¯åŠ¨æ•°æ®å¤„ç†å·¥å…·ã€‚")

# ============================
# å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç›¸å…³å·¥å…·å‡½æ•°
# ============================


# ======== è·¯å¾„å…¼å®¹å‡½æ•° =========
def resource_path(relative_path):
    """å…¼å®¹ PyCharm å¼€å‘ç¯å¢ƒ å’Œ PyInstaller æ‰“åŒ…åçš„è·¯å¾„"""
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)
# ======== åŠ è½½å­¦æ ¡æ•°æ® =========
try:
    school_data_path = resource_path("school_data.xlsx")
    school_df = pd.read_excel(school_data_path)
    VALID_SCHOOL_NAMES = set(school_df['å­¦æ ¡åç§°'].dropna().str.strip())
except Exception as e:
    logging.error(f"è¯»å– school_data.xlsx å‡ºé”™ï¼š{e}")
    VALID_SCHOOL_NAMES = set()


# ======== åŠ è½½æ‹›ç”Ÿä¸“ä¸šæ•°æ® =========
try:
    major_data_path = resource_path("æ‹›ç”Ÿä¸“ä¸š.xlsx")
    major_df = pd.read_excel(major_data_path)
    VALID_MAJOR_COMBOS = set(major_df['æ‹›ç”Ÿä¸“ä¸š'].dropna().astype(str).str.strip())
except Exception as e:
    logging.error(f"è¯»å– æ‹›ç”Ÿä¸“ä¸š.xlsx å‡ºé”™ï¼š{e}")
    VALID_MAJOR_COMBOS = set()

# è®¾ç½®æ—¥å¿—ï¼Œä¾¿äºæ’æŸ¥é—®é¢˜
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.info("å¯åŠ¨é™¢æ ¡æ•°æ®å¤„ç†å·¥å…·ã€‚")

def check_school_name(name):
    if pd.isna(name) or not str(name).strip():
        return 'å­¦æ ¡åç§°ä¸ºç©º'
    return 'åŒ¹é…' if name.strip() in VALID_SCHOOL_NAMES else 'ä¸åŒ¹é…'

def check_major_combo(major, level):
    combo = f"{str(major).strip()}{str(level).strip()}"
    if not major or not level:
        return "æ•°æ®ç¼ºå¤±"
    return "åŒ¹é…" if combo in VALID_MAJOR_COMBOS else "ä¸åŒ¹é…"



CUSTOM_WHITELIST = {
    "å®ç¦æ ¡åŒº", "æ²™æ²³æ ¡åŒº", "ä¸­å¤–åˆä½œåŠå­¦", "ç æµ·æ ¡åŒº", "æ±ŸåŒ—æ ¡åŒº", "æ´¥å—æ ¡åŒº", "å¼€å°æ ¡åŒº",
    "è”åˆåŠå­¦", "æ ¡ä¼åˆä½œ", "åˆä½œåŠå­¦", "å¨æµ·æ ¡åŒº", "æ·±åœ³æ ¡åŒº", "è‹å·æ ¡åŒº", "å¹³æœæ ¡åŒº",
    "æ±Ÿå—æ ¡åŒº", "åˆå·æ ¡åŒº", "é•¿å®‰æ ¡åŒº", "å´‡å®‰æ ¡åŒº", "å—æ ¡åŒº", "ä¸œæ ¡åŒº", "éƒ½å¸‚å›­è‰º", "ç”˜è‚ƒå…°å·"
}

TYPO_DICT = {
    "æ•™åŠ©": "æ•‘åŠ©",
    "æŒ‡è¾‰": "æŒ‡æŒ¥",
    "æ–™å­¦": "ç§‘å­¦",
    "è¯è¨€": "è¯­è¨€",
    "5å3": "5+3",
    "5å3ä¸€ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "â€œ5å3â€ä¸€ä½“åŒ–": "â€œ5+3â€ä¸€ä½“åŒ–",
    "5+31ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "5+3ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "è‰²è¨€": "è‰²ç›²",
    "NIT": "NIIT",
    "è‰²è‚²": "è‰²ç›²",
    "äººå›´": "å…¥å›´",
    "é¡¹æœˆ": "é¡¹ç›®",
    "å¸èŒƒç±»": "å¸ˆèŒƒç±»",
    "æŠ•è¯¾": "æˆè¯¾",
    "å°±è–„": "å°±è¯»",
    "ç”µè¯·": "ç”³è¯·",
    "ä¸­å›½é¢": "ä¸­å›½ç”»",
    "ç«æ•°æ°‘æ—": "å°‘æ•°æ°‘æ—",
    "è‰²è‡ª": "è‰²ç›²",
    "è‰²ç›²è‰²å¼±ç”³æŠ¥": "è‰²ç›²è‰²å¼±æ…æŠ¥",
    "æ•°å­¦ä¸åº”ç”¨æ•°ç¬‘": "æ•°å­¦ä¸åº”ç”¨æ•°å­¦",
    "æ³•å­¦å": "æ³•å­¦+",
    "ä¸­æº´": "ä¸­æ¾³"
}

REGEX_PATTERNS = {
    'excess_punct': re.compile(r'[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+'),
    'outer_punct': re.compile(r'^[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+|[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+$'),
    'consecutive_right': re.compile(r'ï¼‰{2,}')
}
NESTED_PAREN_PATTERN = re.compile(r'ï¼ˆï¼ˆ(.*?)ï¼‰ï¼‰')
CONSECUTIVE_REPEAT_PATTERN = re.compile(r'ï¼ˆ(.+?)ï¼‰\s*ï¼ˆ\1ï¼‰')


def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()


def normalize_brackets(text):
    """ç»Ÿä¸€å„ç§æ‹¬å·ä¸ºä¸­æ–‡æ‹¬å·å¹¶å¤„ç†ä¸å®Œæ•´æ‹¬å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()
    # æ›¿æ¢æ‰€æœ‰æ‹¬å·å˜ä½“ä¸ºä¸­æ–‡æ‹¬å·
    text = re.sub(r'[\{\[\ã€]', 'ï¼ˆ', text)
    text = re.sub(r'[\}\]\ã€‘]', 'ï¼‰', text)
    # è¡¥å…¨å·¦å³æ‹¬å·
    if 'ï¼ˆ' in text and 'ï¼‰' not in text:
        text += 'ï¼‰'
    if 'ï¼‰' in text and 'ï¼ˆ' not in text:
        text = 'ï¼ˆ' + text
    # å¤„ç†è¿ç»­å³æ‹¬å·
    text = REGEX_PATTERNS['consecutive_right'].sub('ï¼‰', text)
    return text


def clean_outer_punctuation(text):
    """æ¸…ç†æœ€å¤–å±‚æ‹¬å·å¤–çš„æ ‡ç‚¹ç¬¦å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()
    text = REGEX_PATTERNS['outer_punct'].sub('', text)
    parts = re.split(r'(ï¼ˆ.*?ï¼‰)', text)
    cleaned_parts = []
    for part in parts:
        if part.startswith('ï¼ˆ') and part.endswith('ï¼‰'):
            cleaned_parts.append(part)
        else:
            cleaned_parts.append(REGEX_PATTERNS['outer_punct'].sub('', part))
    return ''.join(cleaned_parts)


def check_school_name(name):
    if pd.isna(name) or not str(name).strip():
        return 'å­¦æ ¡åç§°ä¸ºç©º'
    return 'åŒ¹é…' if name.strip() in VALID_SCHOOL_NAMES else 'ä¸åŒ¹é…'


def check_score_consistency(row):
    """æ£€æŸ¥åˆ†æ•°ä¸€è‡´æ€§ï¼šæœ€é«˜åˆ† >= å¹³å‡åˆ† >= æœ€ä½åˆ†"""
    issues = []

    try:
        max_score = float(row['æœ€é«˜åˆ†']) if pd.notna(row['æœ€é«˜åˆ†']) else None
        avg_score = float(row['å¹³å‡åˆ†']) if pd.notna(row['å¹³å‡åˆ†']) else None
        min_score = float(row['æœ€ä½åˆ†']) if pd.notna(row['æœ€ä½åˆ†']) else None

        if max_score is not None and avg_score is not None and max_score < avg_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < å¹³å‡åˆ†({avg_score})")

        if max_score is not None and min_score is not None and max_score < min_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < æœ€ä½åˆ†({min_score})")

        if avg_score is not None and min_score is not None and avg_score < min_score:
            issues.append(f"å¹³å‡åˆ†({avg_score}) < æœ€ä½åˆ†({min_score})")

    except ValueError as e:
        issues.append(f"åˆ†æ•°æ ¼å¼é”™è¯¯: {str(e)}")

    return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜'

def check_major_combo(major, level):
    combo = f"{str(major).strip()}{str(level).strip()}"
    if not major or not level:
        return "æ•°æ®ç¼ºå¤±"
    return "åŒ¹é…" if combo in VALID_MAJOR_COMBOS else "ä¸åŒ¹é…"


def analyze_and_fix(text):
    if pd.isna(text) or not str(text).strip():
        return text, []
    text = normalize_brackets(text)
    text = clean_outer_punctuation(text)
    original_text = text
    issues = []
    if text in CUSTOM_WHITELIST:
        logging.info(f"è·³è¿‡ç™½åå•ä¸­çš„å†…å®¹ï¼š{text}")
        return text, []
    # æ£€æŸ¥æ‹¬å·åŒ¹é…
    left_count = text.count('ï¼ˆ')
    right_count = text.count('ï¼‰')
    if left_count != right_count:
        if left_count > right_count:
            text += 'ï¼‰' * (left_count - right_count)
            issues.append(f"è¡¥å……ç¼ºå¤±å³æ‹¬å· {left_count - right_count} ä¸ª")
        else:
            text = 'ï¼ˆ' * (right_count - left_count) + text
            issues.append(f"è¡¥å……ç¼ºå¤±å·¦æ‹¬å· {right_count - left_count} ä¸ª")
    new_text = re.sub(r'ï¼ˆï¼ˆ(.*?)ï¼‰ï¼‰', r'ï¼ˆ\1ï¼‰', text)
    if new_text != text:
        issues.append("å­˜åœ¨åµŒå¥—æ‹¬å·")
    text = new_text
    text, n = CONSECUTIVE_REPEAT_PATTERN.subn(r'ï¼ˆ\1ï¼‰', text)
    if n > 0:
        issues.append("å­˜åœ¨é‡å¤æ‹¬å·å†…å®¹")

    def fix_paren(match):
        content = match.group(1)
        fixed = content.lstrip("ï¼Œã€,;ï¼›").rstrip("ï¼Œã€,;ï¼›")
        if fixed != content:
            if content and content[0] in "ï¼Œã€,;ï¼›":
                issues.append(f"æ‹¬å·å†…å®¹å¼€å¤´å¤šæ ‡ç‚¹ï¼š'{content}'")
            if content and content[-1] in "ï¼Œã€,;ï¼›":
                issues.append(f"æ‹¬å·å†…å®¹ç»“å°¾å¤šæ ‡ç‚¹ï¼š'{content}'")
        return f'ï¼ˆ{fixed}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', fix_paren, text)
    seen = set()

    def remove_duplicates(match):
        content = match.group(1)
        if content in seen:
            issues.append(f"é‡å¤å†…å®¹ï¼š{content}")
            return ''
        else:
            seen.add(content)
            return f'ï¼ˆ{content}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', remove_duplicates, text)
    text = REGEX_PATTERNS['excess_punct'].sub(lambda m: m.group(0)[0], text)

    paren_contents = re.findall(r'ï¼ˆ(.*?)ï¼‰', original_text)
    unique_contents = list(dict.fromkeys(paren_contents))
    for i in range(len(unique_contents)):
        for j in range(i + 1, len(unique_contents)):
            if similar(unique_contents[i], unique_contents[j]) >= 0.8:
                issues.append(f"ç›¸ä¼¼é‡å¤ï¼š'{unique_contents[i]}' ä¸ '{unique_contents[j]}'")
    # ç›´æ¥åŒ¹é…ä¿®æ­£å·²çŸ¥é”™åˆ«å­—
    for typo, correct in TYPO_DICT.items():
        if typo in text:
            text = text.replace(typo, correct)
            issues.append(f"é”™åˆ«å­—ï¼š'{typo}'â†’'{correct}'")

    # åˆ©ç”¨jiebaè¿›è¡Œåˆ†è¯ï¼Œå¢å¼ºé”™åˆ«å­—æ£€æµ‹
    tokens = jieba.lcut(text)
    for token in tokens:
        if len(token) < 2:
            continue
        for typo, correct in TYPO_DICT.items():
            # å¦‚æœåˆ†è¯ä¸é”™åˆ«å­—è¯æ¡ç›¸ä¼¼åº¦å¾ˆé«˜ï¼ˆä½†å¹¶éå®Œå…¨ä¸€è‡´ï¼‰ï¼Œæç¤ºç–‘ä¼¼é”™åˆ«å­—
            if token != typo:
                ratio = SequenceMatcher(None, token, typo).ratio()
                if ratio >= 0.9:
                    issues.append(f"ç–‘ä¼¼é”™åˆ«å­—ï¼š'{token}' å¯èƒ½åº”ä¸º '{correct}'")
    return text, issues


def process_chunk(chunk):
    # å­¦æ ¡åŒ¹é…æ£€æŸ¥ï¼ˆå‡è®¾åˆ—åæ˜¯â€œå­¦æ ¡åç§°â€ï¼‰
    chunk['å­¦æ ¡åŒ¹é…ç»“æœ'] = chunk['å­¦æ ¡åç§°'].apply(check_school_name)

    # æ‹›ç”Ÿä¸“ä¸šåŒ¹é…æ£€æŸ¥ï¼ˆç»„åˆï¼šä¸“ä¸šåç§° + ç§‘ç±»ï¼‰
    chunk['æ‹›ç”Ÿä¸“ä¸šåŒ¹é…ç»“æœ'] = chunk.apply(lambda row: check_major_combo(row['æ‹›ç”Ÿä¸“ä¸š'], row['ä¸€çº§å±‚æ¬¡']), axis=1)


    # å¤„ç†å¤‡æ³¨æ£€æŸ¥
    chunk['å¤‡æ³¨æ£€æŸ¥ç»“æœ'] = chunk['ä¸“ä¸šå¤‡æ³¨'].apply(lambda x: 'ï¼›'.join(analyze_and_fix(x)[1]) if x else 'æ— é—®é¢˜')
    chunk['ä¿®æ”¹åå¤‡æ³¨'] = chunk['ä¸“ä¸šå¤‡æ³¨'].apply(lambda x: analyze_and_fix(x)[0] if x else 'æ— é—®é¢˜')

    # æ£€æŸ¥åˆ†æ•°ä¸€è‡´æ€§
    chunk['åˆ†æ•°æ£€æŸ¥ç»“æœ'] = chunk.apply(check_score_consistency, axis=1)

    # å¤„ç†é€‰ç§‘è¦æ±‚ï¼ˆå‡è®¾åˆ—åæ˜¯â€œé€‰ç§‘è¦æ±‚â€ï¼‰
    def process_subject_requirement(requirement):
        if pd.isna(requirement) or not str(requirement).strip():
            return ["", ""]

        requirement = str(requirement).strip()

        # å¤„ç†â€œä¸é™â€çš„æƒ…å†µ
        if "ä¸é™" in requirement:
            return ["ä¸é™ç§‘ç›®ä¸“ä¸šç»„", ""]

        # å¦‚æœæ˜¯å•ä¸ªå­—ï¼Œè§†ä¸ºä¸€ä¸ªç§‘ç›®
        if len(requirement) == 1:
            return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", requirement]

        # å¤„ç†â€œä¸”â€çš„æƒ…å†µ
        if "ä¸”" in requirement:
            parts = requirement.split("ä¸”")
            return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", "".join(parts).replace("ä¸”", "")]  # å»é™¤â€œä¸”â€è¿æ¥è¯

        # å¤„ç†â€œæˆ–â€çš„æƒ…å†µ
        if "æˆ–" in requirement:
            parts = requirement.split("æˆ–")
            return ["å¤šé—¨é€‰è€ƒ", "".join(parts).replace("æˆ–", "")]  # å»é™¤â€œæˆ–â€è¿æ¥è¯

        return ["", ""]

    # åº”ç”¨å¤„ç†å‡½æ•°åˆ°â€œé€‰ç§‘è¦æ±‚â€åˆ—ï¼Œå¹¶å¡«å……åˆ°ç›¸åº”çš„åˆ—
    chunk[['é€‰ç§‘è¦æ±‚è¯´æ˜', 'æ¬¡é€‰']] = chunk['é€‰ç§‘è¦æ±‚'].apply(
        lambda x: pd.Series(process_subject_requirement(x)))

    # æ£€æŸ¥æ˜¯å¦æœ‰â€œæ‹›ç”Ÿç§‘ç±»â€å­—æ®µï¼Œå¹¶æ›¿æ¢â€œç‰©ç†â€ä¸â€œå†å²â€åˆ°â€œç‰©ç†ç±»â€å’Œâ€œå†å²ç±»â€
    if 'æ‹›ç”Ÿç§‘ç±»' in chunk.columns:
        chunk['æ‹›ç”Ÿç§‘ç±»'] = chunk['æ‹›ç”Ÿç§‘ç±»'].replace({'ç‰©ç†': 'ç‰©ç†ç±»', 'å†å²': 'å†å²ç±»'})

    # æ£€æŸ¥æ˜¯å¦æœ‰â€œæ‹›ç”Ÿç§‘ç±»â€å­—æ®µï¼Œå¹¶æå–é¦–å­—åˆ°â€œé¦–é€‰ç§‘ç›®â€å­—æ®µ
    if 'æ‹›ç”Ÿç§‘ç±»' in chunk.columns:
        chunk['é¦–é€‰ç§‘ç›®'] = chunk['æ‹›ç”Ÿç§‘ç±»'].apply(
            lambda x: str(x)[0] if pd.notna(x) and x in ['ç‰©ç†ç±»', 'å†å²ç±»','ç‰©ç†', 'å†å²'] else "")

    return chunk

# ============================
# é™¢æ ¡åˆ†æå–ç›¸å…³å‡½æ•°
# ============================
expected_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡',
    'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', 'æ•°æ®æ¥æº',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
]
columns_to_convert = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'
]

def process_score_file(file_path):
    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€é«˜åˆ†': str,
            'æœ€ä½åˆ†': str,
            'å¹³å‡åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰': str,
            'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    missing_columns = [col for col in expected_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df = df.dropna(subset=['æœ€ä½åˆ†'])

    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'].replace([None], '')

    try:
        group_with_code = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'ä¸“ä¸šç»„ä»£ç ', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰',
                           'æ‹›ç”Ÿä»£ç ']
        group_without_code = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿä»£ç ']

        min_indices_code = df.groupby(group_with_code)['æœ€ä½åˆ†'].idxmin()
        min_indices_nocode = df.groupby(group_without_code)['æœ€ä½åˆ†'].idxmin()

        selected_indices = list(set(min_indices_code).union(set(min_indices_nocode)))
        result = df.loc[selected_indices].copy()

        # è¡¥å……å½•å–äººæ•°ä¸ºåˆ†ç»„æ€»å’Œ
        code_groups = df.groupby(group_with_code)['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()
        nocode_groups = df.groupby(group_without_code)['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()

        def get_group_total(row):
            if row['ä¸“ä¸šç»„ä»£ç ']:
                key = tuple(row[col] for col in group_with_code)
                return code_groups.get(key, '')
            else:
                key = tuple(row[col] for col in group_without_code)
                return nocode_groups.get(key, '')

        result['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(get_group_total, axis=1)

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    selected_columns = [col for col in expected_columns if col in result.columns]
    result = result[selected_columns]

    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            result.to_excel(writer, index=False)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']

            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in result.columns:
                    col_idx = result.columns.get_loc(col) + 1
                    for row in range(2, len(result) + 2):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT

            for col in columns_to_convert:
                if col in result.columns and col not in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                    col_idx = result.columns.get_loc(col) + 1
                    for cell in \
                    list(worksheet.iter_cols(min_col=col_idx, max_col=col_idx, min_row=2, values_only=False))[0]:
                        cell.number_format = numbers.FORMAT_TEXT

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")

# ============================
# å­¦ä¸šæ¡¥æ•°æ®å¤„ç†å‡½æ•°
# ============================
def process_remarks_file(file_path, progress_callback=None):
    try:
        # è¯»å–æ–‡ä»¶æ—¶ï¼Œç¡®ä¿è¿™äº›å­—æ®µå§‹ç»ˆä»¥å­—ç¬¦ä¸²æ ¼å¼è¯»å–
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
        }, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")
    for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
        if col in df.columns:
            df[col] = df[col].astype(str)
    target_col = None
    for col in df.columns:
        if "ä¸“ä¸šå¤‡æ³¨" in str(col):
            target_col = col
            break
    if not target_col:
        raise Exception("æœªæ‰¾åˆ°'ä¸“ä¸šå¤‡æ³¨'ç›¸å…³åˆ—")
    if target_col != 'ä¸“ä¸šå¤‡æ³¨':
        df = df.rename(columns={target_col: 'ä¸“ä¸šå¤‡æ³¨'})
    chunks = []
    for i in range(0, len(df), 1000):
        chunks.append(df.iloc[i:i + 1000].copy())
    results = {}
    total_chunks = len(chunks)
    with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
        future_to_index = {executor.submit(process_chunk, chunk): idx for idx, chunk in enumerate(chunks)}
        for count, future in enumerate(as_completed(future_to_index)):
            idx = future_to_index[future]
            results[idx] = future.result()
            if progress_callback:
                progress_callback(count + 1, total_chunks)
    ordered_results = [results[i] for i in sorted(results.keys())]
    final_result = pd.concat(ordered_results)
    output_path = file_path.replace('.xlsx', '_æ£€æŸ¥ç»“æœ.xlsx')
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            final_result.to_excel(writer, index=False)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']
            # ä¿æŒæŒ‡å®šåˆ—ä»ç¬¬ä¸‰è¡Œå¼€å§‹æ–‡æœ¬æ ¼å¼
            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in final_result.columns:
                    col_idx = final_result.columns.get_loc(col) + 1  # è½¬æ¢ä¸ºExcelåˆ—å·ï¼ˆA=1ï¼‰
                    # ä»ç¬¬ä¸‰è¡Œå¼€å§‹è®¾ç½®æ ¼å¼ï¼ˆExcelè¡Œå·ä¸º3ï¼Œå¯¹åº”Pythonçš„ç´¢å¼•ä¸º2ï¼‰
                    for row in range(3, len(final_result) + 2):  # å·¥ä½œè¡¨è¡Œå·ä»3å¼€å§‹ï¼ˆç´¢å¼•2ï¼‰
                        cell = worksheet.cell(row=row, column=col_idx)
                        cell.value = final_result.iloc[row - 3][col]  # æ•°æ®ä»ç¬¬ä¸‰è¡Œå¼€å§‹å¡«å……
                        cell.number_format = numbers.FORMAT_TEXT
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–‡ä»¶é”™è¯¯ï¼š{e}")
    return output_path

# ============================
# ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†
# ============================

def process_segmentation_file(file_path):
    output_path = os.path.splitext(file_path)[0] + "_æ ¡éªŒç»“æœ.xlsx"
    wb = openpyxl.load_workbook(file_path)
    ws = wb.active

    ws['E7'] = 'ç´¯è®¡äººæ•°æ ¡éªŒç»“æœ'
    ws['F7'] = 'åˆ†æ•°æ ¡éªŒç»“æœ'
    ws['F2'] = 'å¹´ä»½æ ¡éªŒ'  # âœ… ä¿ç•™æ ‡é¢˜

    # æ ¡éªŒ B2 æ˜¯å¦ä¸º 2025
    if ws['B2'].value != 2025:
        ws['G2'] = f"Ã— åº”ä¸º2025ï¼Œå½“å‰ä¸ºï¼š{ws['B2'].value}"
    else:
        ws['G2'] = "âˆš"

    region = ws['B3'].value
    suffix = "-750"
    if region == "ä¸Šæµ·":
        suffix = "-660"
    elif region == "æµ·å—":
        suffix = "-900"

    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    # ---------- ç¬¬8è¡Œç‰¹æ®Šå¤„ç† ----------
    row = 8
    curr_score = ws[f"A{row}"].value
    curr_num = ws[f"B{row}"].value
    curr_total = ws[f"C{row}"].value

    try:
        score_int = int(float(str(curr_score).split('-')[0]))
    except:
        score_int = None

    inserted = False
    if curr_total is not None:
        if curr_num is None or curr_num == "":
            # æ²¡æœ‰äººæ•° â†’ è‡ªåŠ¨è®¡ç®—
            if row == 8:
                ws[f"B{row}"] = curr_total
            else:
                prev_total = ws[f"C{row - 1}"].value
                if prev_total is not None:
                    ws[f"B{row}"] = curr_total - prev_total
        else:
            # æœ‰äººæ•°å’Œç´¯è®¡äººæ•°ä¸ä¸€è‡´æ—¶æ’å…¥è¡¥æ–­ç‚¹è¡Œ
            if curr_num != curr_total:
                try:
                    insert_score = score_int + 1
                    insert_num = curr_total - curr_num
                    ws.insert_rows(row)
                    ws[f"A{row}"] = f"{insert_score}{suffix}"  # âœ… ä»…åŠ åç¼€åœ¨æ–°å¢è¡Œ
                    ws[f"B{row}"] = insert_num
                    ws[f"C{row}"] = insert_num
                    for col in ['A', 'B', 'C', 'E', 'F']:
                        ws[f"{col}{row}"].fill = yellow_fill
                    ws[f"E{row}"] = "è¡¥æ–­ç‚¹"
                    ws[f"F{row}"] = "è¡¥æ–­ç‚¹"
                    inserted = True
                except:
                    pass

    # ä»…å½“æ²¡æœ‰æ’å…¥è¡Œæ—¶ï¼Œç¬¬8è¡ŒåŠ åç¼€
    if not inserted and score_int is not None:
        ws[f"A{row}"] = f"{score_int}{suffix}"

    # ---------- è¡¥æ–­ç‚¹é€»è¾‘ ----------
    while row < ws.max_row:
        curr = ws[f"A{row}"].value
        next = ws[f"A{row + 1}"].value
        try:
            curr_score_int = int(str(curr).split('-')[0])
            next_score_int = int(str(next).split('-')[0])
        except:
            row += 1
            continue

        if curr_score_int - next_score_int > 1:
            missing_score = curr_score_int - 1
            ws.insert_rows(row + 1)
            ws[f"A{row + 1}"] = missing_score
            ws[f"B{row + 1}"] = 0
            ws[f"C{row + 1}"] = ws[f"C{row}"].value
            for col in ['A', 'B', 'C', 'E', 'F']:
                ws[f"{col}{row + 1}"].fill = yellow_fill
            ws[f"E{row + 1}"] = "è¡¥æ–­ç‚¹"
            ws[f"F{row + 1}"] = "è¡¥æ–­ç‚¹"
        else:
            row += 1

    # ---------- æ ¡éªŒä¸è‡ªåŠ¨è¡¥äººæ•° ----------
    for row in range(8, ws.max_row + 1):
        curr_score = ws[f"A{row}"].value
        curr_num = ws[f"B{row}"].value
        curr_total = ws[f"C{row}"].value
        prev_total = ws[f"C{row - 1}"].value if row > 8 else None
        prev_score = ws[f"A{row - 1}"].value if row > 8 else None

        # è‡ªåŠ¨è¡¥äººæ•°
        if (curr_num is None or curr_num == "") and curr_total is not None:
            if row == 8:
                ws[f"B{row}"] = curr_total
                curr_num = curr_total
            elif prev_total is not None:
                try:
                    calc = curr_total - prev_total
                    ws[f"B{row}"] = calc
                    curr_num = calc
                except:
                    pass

        # æ ¡éªŒç´¯è®¡äººæ•°
        if prev_total is not None and curr_num is not None and curr_total is not None:
            expected_total = prev_total + curr_num
            if expected_total == curr_total:
                if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"E{row}"] = "âˆš"
            else:
                if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"E{row}"] = f"Ã— åº”ä¸º{expected_total}"

        # æ ¡éªŒåˆ†æ•°å·®
        try:
            curr_score_num = float(str(curr_score).split('-')[0])
            prev_score_num = float(str(prev_score).split('-')[0])
        except:
            curr_score_num = prev_score_num = None

        if curr_score_num is not None and prev_score_num is not None:
            diff = prev_score_num - curr_score_num
            if diff == 1:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = "âˆš"
            else:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = f"Ã— å·®å€¼{diff}"
        else:
            if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"F{row}"] = "Ã— åˆ†æ•°éæ•°å­—ï¼Œæ— æ³•æ ¡éªŒ"

    wb.save(output_path)
    return output_path

# ============================
# Streamlité¡µé¢å¸ƒå±€
# ============================
# é¡µé¢æ ‡é¢˜
st.title("ğŸ“Š æ•°æ®å¤„ç†å·¥å…·")
st.markdown("---")

# åŠŸèƒ½è¯´æ˜
with st.expander("ğŸ“Œ åŠŸèƒ½è¯´æ˜", expanded=True):
    st.markdown("""
    1. ä¸Šä¼ çš„æ–‡ä»¶ä½¿ç”¨åº“ä¸­ä¸“ä¸šåˆ†ã€é™¢æ ¡åˆ†ã€æ‹›ç”Ÿè®¡åˆ’ã€ä¸€åˆ†ä¸€æ®µçš„æ¨¡æ¿ï¼Œç›´æ¥ä¸Šä¼ å³å¯ï¼Œæ— éœ€åˆ å‡
    2. å¤‡æ³¨æ£€æŸ¥ä¸­ï¼Œæ£€æŸ¥å‡ºæ¥æ‹¬å·æœ‰é—®é¢˜çš„å†…å®¹è¿˜éœ€è¦è‡ªå·±å†è¿‡ä¸€éï¼›æ•´ä¸ªæ–‡ä»¶çš„å¤‡æ³¨éœ€è¦å¤§æ¦‚çœ‹çœ‹æœ‰æ²¡æœ‰é”™åˆ«å­—
    3. é™¢æ ¡åˆ†åœ¨æå–æ—¶ä¼šå¯¹æ‹›ç”Ÿä»£ç ä¸€åˆ—è¿›è¡Œæ ¡éªŒï¼Œå‡ºç°è¿‡é”€å”®æä¾›çš„æ•°æ®ä¸­ã€åŒä¸€ä¸ªå­¦æ ¡ã€çœä»½ã€‘æ‹›ç”Ÿä»£ç ä¸å…¨çš„æƒ…å†µï¼Œæå–é™¢æ ¡åˆ†æ—¶ä¼šå¤šæå–æ•°æ®ï¼Œéœ€è¦äººå·¥æŸ¥éªŒï¼
    4. æ ¡éªŒä¸€åˆ†ä¸€æ®µæ—¶ï¼Œå†…å®¹ä¸èƒ½ä¸ºæ–‡æœ¬æ ¼å¼
    """)

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3 = st.tabs(["é™¢æ ¡åˆ†æå–", "å­¦ä¸šæ¡¥æ•°æ®å¤„ç†", "ä¸€åˆ†ä¸€æ®µæ ¡éªŒ"])

# ====================== é™¢æ ¡åˆ†æå– ======================
with tab1:
    st.header("é™¢æ ¡åˆ†æå–")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="score_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_score_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_score_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="processed_scores.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== å­¦ä¸šæ¡¥æ•°æ®å¤„ç† ======================
with tab2:
    st.header("å­¦ä¸šæ¡¥æ•°æ®å¤„ç†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="remarks_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_remarks"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_remarks.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())


                # è¿›åº¦å›è°ƒå‡½æ•°
                def update_progress(current, total):
                    percent = int((current / total) * 100)
                    progress_bar.progress(percent)
                    status_text.text(f"å¤„ç†ä¸­... {percent}%")


                # å¤„ç†æ–‡ä»¶
                output_path = process_remarks_file(temp_file, progress_callback=update_progress)

                # å¤„ç†å®Œæˆ
                progress_bar.progress(100)
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="processed_remarks.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸€åˆ†ä¸€æ®µæ ¡éªŒ ======================
with tab3:
    st.header("ä¸€åˆ†ä¸€æ®µæ ¡éªŒ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="segmentation_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_segmentation"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_segmentation.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_segmentation_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_segmentation_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="processed_segmentation.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# é¡µè„š
st.markdown("---")
st.markdown("Â© 2025 æ•°æ®å¤„ç†ä¸­å¿ƒ", unsafe_allow_html=True)

# æ›´æ–°æ—¥å¿—å¯¹è¯æ¡†
if not os.path.exists("no_update_log_flag.txt"):
    with st.expander("ğŸ“¢ ç‰ˆæœ¬æ›´æ–°", expanded=False):
        st.markdown("""
        ### 2025.6.6æ›´æ–°
        â€¢ "ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"ä¼˜åŒ–
          - è‡ªåŠ¨è¡¥å……"æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰
          - åªæœ‰ç´¯è®¡äººæ•°æ²¡æœ‰äººæ•°æ—¶ï¼Œå¯è®¡ç®—äººæ•°ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ
          - è¡¥æ–­ç‚¹çš„åˆ†æ•°æ ‡æ³¨é¢œè‰²ï¼Œå¹¶åœ¨åˆ†æ•°å’Œäººæ•°æ ¡éªŒä¸­æ ‡æ³¨"è¡¥æ–­ç‚¹"

        ### å†å²æ›´æ–°

        #### 2025.4.14æ›´æ–°
        â€¢ æ‹›ç”Ÿä»£ç å’Œä¸“ä¸šä»£ç ä¿æŒæ–‡æœ¬æ ¼å¼
        â€¢ å¢åŠ åŠŸèƒ½è¯´æ˜
        â€¢ ä¼˜åŒ–å·¥å…·ç•Œé¢

        #### 2025.4.16æ›´æ–°
        â€¢ ä¼˜åŒ–äº†é™¢æ ¡åˆ†æå–å¤„ç†é€»è¾‘

        #### 2025.5.22æ›´æ–°
        â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†æå–ä¸­å½•å–äººæ•°çš„å¤„ç†é€»è¾‘ï¼ˆå»ºè®®è¿›è¡ŒæŠ½æŸ¥ï¼‰
        â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†æœ€é«˜åˆ†ã€å¹³å‡åˆ†ã€æœ€ä½åˆ†çš„æ ¡éªŒï¼Œä¼šåœ¨æœ€ååŠ ä¸€åˆ—æ ¡éªŒç»“æœ

        #### 2025.5.23æ›´æ–°
        â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†å­¦æ ¡åç§°å’Œæ‹›ç”Ÿä¸“ä¸šçš„åŒ¹é…

        #### 2025.5.27æ›´æ–°
        â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­ï¼Œå¢åŠ äº†"æ‹›ç”Ÿç§‘ç±»"ã€"é¦–é€‰ç§‘ç›®"ã€"é€‰ç§‘è¦æ±‚"ï¼Œ"æ¬¡é€‰ç§‘ç›®"çš„å¤„ç†
          - å­¦ä¸šæ¡¥æä¾›çš„"3+1+2"çœä»½çš„æ‹›ç”Ÿç§‘ç±»ä¸º"ç‰©ç†"ã€"å†å²"ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†çš„"ç‰©ç†ç±»"ã€"å†å²ç±»"
          - "3+1+2"çœä»½çš„é¦–é€‰ç§‘ç›®å¯ä»¥ç›´æ¥æ ¹æ®æ‹›ç”Ÿç§‘ç±»æå–
          - æ–°å¢äº†é€‰ç§‘è¦æ±‚ã€æ¬¡é€‰ç§‘ç›®çš„å¤„ç†ï¼Œå¯ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†ï¼ˆå¤„ç†åçš„æ•°æ®åœ¨æ–‡æ¡£æœ€åå‡ åˆ—ï¼‰

        #### 2025.5.30æ›´æ–°
        â€¢ æ–°å¢"ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"
          - å¯ç›´æ¥æ ¡éªŒåˆ†æ•°ã€ç´¯è®¡äººæ•°
          - è‡ªåŠ¨è¡¥æ–­ç‚¹
          - è‡ªåŠ¨å¢åŠ "æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰
        """)

        if st.checkbox("ä¸å†æ˜¾ç¤ºæ›´æ–°æç¤º"):
            with open("no_update_log_flag.txt", "w", encoding="utf-8") as f:
                f.write("ç”¨æˆ·é€‰æ‹©ä¸å†æç¤ºæ›´æ–°æ—¥å¿—")
            st.success("å·²è®¾ç½®ä¸å†æ˜¾ç¤ºæ›´æ–°æç¤º")