import streamlit as st
import pandas as pd
import os
import logging
import re
import streamlit.components.v1 as components
from difflib import SequenceMatcher
from concurrent.futures import ThreadPoolExecutor, as_completed
import openpyxl
from openpyxl.styles import PatternFill, Alignment
from openpyxl.styles import numbers
import base64
import sys
from io import BytesIO
import requests
import tempfile
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from PIL import Image
from openpyxl.utils import get_column_letter


# ============================
# åˆå§‹åŒ–è®¾ç½®
# ============================
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.info("å¯åŠ¨æ•°æ®å¤„ç†å·¥å…·ã€‚")


# ============================
# å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç›¸å…³å·¥å…·å‡½æ•°
# ============================

# ======== è·¯å¾„å…¼å®¹å‡½æ•° =========
def resource_path(relative_path):
    """å…¼å®¹ PyCharm å¼€å‘ç¯å¢ƒ å’Œ PyInstaller æ‰“åŒ…åçš„è·¯å¾„"""
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)


# ======== åŠ è½½å­¦æ ¡æ•°æ® =========
try:
    school_data_path = resource_path("school_data.xlsx")
    school_df = pd.read_excel(school_data_path)
    VALID_SCHOOL_NAMES = set(school_df['å­¦æ ¡åç§°'].dropna().str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_SCHOOL_NAMES)} ä¸ªæœ‰æ•ˆå­¦æ ¡åç§°")
except Exception as e:
    logging.error(f"è¯»å– school_data.xlsx å‡ºé”™ï¼š{e}")
    VALID_SCHOOL_NAMES = set()
    st.warning("å­¦æ ¡æ•°æ®åŠ è½½å¤±è´¥ï¼Œå­¦æ ¡åç§°æ£€æŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨")

# ======== åŠ è½½æ‹›ç”Ÿä¸“ä¸šæ•°æ® =========
try:
    major_data_path = resource_path("æ‹›ç”Ÿä¸“ä¸š.xlsx")
    major_df = pd.read_excel(major_data_path)
    VALID_MAJOR_COMBOS = set(major_df['æ‹›ç”Ÿä¸“ä¸š'].dropna().astype(str).str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_MAJOR_COMBOS)} ä¸ªæœ‰æ•ˆä¸“ä¸šç»„åˆ")
except Exception as e:
    logging.error(f"è¯»å– æ‹›ç”Ÿä¸“ä¸š.xlsx å‡ºé”™ï¼š{e}")
    VALID_MAJOR_COMBOS = set()
    st.warning("ä¸“ä¸šæ•°æ®åŠ è½½å¤±è´¥ï¼Œä¸“ä¸šåŒ¹é…åŠŸèƒ½å°†ä¸å¯ç”¨")


def check_school_name(name):
    if pd.isna(name) or not str(name).strip():
        return 'å­¦æ ¡åç§°ä¸ºç©º'
    return 'åŒ¹é…' if name.strip() in VALID_SCHOOL_NAMES else 'ä¸åŒ¹é…'


def check_major_combo(major, level):
    if pd.isna(major) or pd.isna(level):
        return "æ•°æ®ç¼ºå¤±"
    combo = f"{str(major).strip()}{str(level).strip()}"
    return "åŒ¹é…" if combo in VALID_MAJOR_COMBOS else "ä¸åŒ¹é…"


CUSTOM_WHITELIST = {
    "å®ç¦æ ¡åŒº", "æ²™æ²³æ ¡åŒº", "ä¸­å¤–åˆä½œåŠå­¦", "ç æµ·æ ¡åŒº", "æ±ŸåŒ—æ ¡åŒº", "æ´¥å—æ ¡åŒº", "å¼€å°æ ¡åŒº",
    "è”åˆåŠå­¦", "æ ¡ä¼åˆä½œ", "åˆä½œåŠå­¦", "å¨æµ·æ ¡åŒº", "æ·±åœ³æ ¡åŒº", "è‹å·æ ¡åŒº", "å¹³æœæ ¡åŒº",
    "æ±Ÿå—æ ¡åŒº", "åˆå·æ ¡åŒº", "é•¿å®‰æ ¡åŒº", "å´‡å®‰æ ¡åŒº", "å—æ ¡åŒº", "ä¸œæ ¡åŒº", "éƒ½å¸‚å›­è‰º", "ç”˜è‚ƒå…°å·"
}

TYPO_DICT = {
    "æ•™åŠ©": "æ•‘åŠ©",
    "æŒ‡è¾‰": "æŒ‡æŒ¥",
    "æ–™å­¦": "ç§‘å­¦",
    "è¯è¨€": "è¯­è¨€",
    "5å3": "5+3",
    "5å3ä¸€ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "â€œ5å3â€ä¸€ä½“åŒ–": "â€œ5+3â€ä¸€ä½“åŒ–",
    "5+31ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "5+3ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "è‰²è¨€": "è‰²ç›²",
    "NIT": "NIIT",
    "è‰²è‚²": "è‰²ç›²",
    "äººå›´": "å…¥å›´",
    "é¡¹æœˆ": "é¡¹ç›®",
    "å¸èŒƒç±»": "å¸ˆèŒƒç±»",
    "æŠ•è¯¾": "æˆè¯¾",
    "å°±è–„": "å°±è¯»",
    "ç”µè¯·": "ç”³è¯·",
    "ä¸­å›½é¢": "ä¸­å›½ç”»",
    "ç«æ•°æ°‘æ—": "å°‘æ•°æ°‘æ—",
    "è‰²è‡ª": "è‰²ç›²",
    "è‰²ç›²è‰²å¼±ç”³æŠ¥": "è‰²ç›²è‰²å¼±æ…æŠ¥",
    "æ•°å­¦ä¸åº”ç”¨æ•°ç¬‘": "æ•°å­¦ä¸åº”ç”¨æ•°å­¦",
    "æ³•å­¦å": "æ³•å­¦+",
    "æµ£æµ·æ ¡åŒº": "æ»¨æµ·æ ¡åŒº",
    "ä¸­æº´": "ä¸­æ¾³"
}

REGEX_PATTERNS = {
    'excess_punct': re.compile(r'[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+'),
    'outer_punct': re.compile(r'^[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+|[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+$'),
    'consecutive_right': re.compile(r'ï¼‰{2,}')
}
NESTED_PAREN_PATTERN = re.compile(r'ï¼ˆï¼ˆ(.*?)ï¼‰ï¼‰')
CONSECUTIVE_REPEAT_PATTERN = re.compile(r'ï¼ˆ(.+?)ï¼‰\s*ï¼ˆ\1ï¼‰')


def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()


def normalize_brackets(text):
    """ç»Ÿä¸€å„ç§æ‹¬å·ä¸ºä¸­æ–‡æ‹¬å·å¹¶å¤„ç†ä¸å®Œæ•´æ‹¬å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()

    # æ›¿æ¢æ‰€æœ‰æ‹¬å·å˜ä½“ä¸ºä¸­æ–‡æ‹¬å·
    text = re.sub(r'[{\[ã€]', 'ï¼ˆ', text)  # å·¦æ‹¬å·
    text = re.sub(r'[}\]ã€‘]', 'ï¼‰', text)  # å³æ‹¬å·
    text = re.sub(r'[<ã€Š]', 'ï¼ˆ', text)  # å·¦ä¹¦åå·æ›¿æ¢ä¸ºå·¦æ‹¬å·
    text = re.sub(r'[>ã€‹]', 'ï¼‰', text)  # å³ä¹¦åå·æ›¿æ¢ä¸ºå³æ‹¬å·

    return text


def clean_outer_punctuation(text):
    """æ¸…ç†æœ€å¤–å±‚æ‹¬å·å¤–çš„æ ‡ç‚¹ç¬¦å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()
    text = REGEX_PATTERNS['outer_punct'].sub('', text)
    parts = re.split(r'(ï¼ˆ.*?ï¼‰)', text)
    cleaned_parts = []
    for part in parts:
        if part.startswith('ï¼ˆ') and part.endswith('ï¼‰'):
            cleaned_parts.append(part)
        else:
            cleaned_parts.append(REGEX_PATTERNS['outer_punct'].sub('', part))
    return ''.join(cleaned_parts)


def check_score_consistency(row):
    """æ£€æŸ¥åˆ†æ•°ä¸€è‡´æ€§ï¼šæœ€é«˜åˆ† >= å¹³å‡åˆ† >= æœ€ä½åˆ†"""
    issues = []
    try:
        max_score = float(row['æœ€é«˜åˆ†']) if pd.notna(row['æœ€é«˜åˆ†']) else None
        avg_score = float(row['å¹³å‡åˆ†']) if pd.notna(row['å¹³å‡åˆ†']) else None
        min_score = float(row['æœ€ä½åˆ†']) if pd.notna(row['æœ€ä½åˆ†']) else None

        if max_score is not None and avg_score is not None and max_score < avg_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < å¹³å‡åˆ†({avg_score})")

        if max_score is not None and min_score is not None and max_score < min_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < æœ€ä½åˆ†({min_score})")

        if avg_score is not None and min_score is not None and avg_score < min_score:
            issues.append(f"å¹³å‡åˆ†({avg_score}) < æœ€ä½åˆ†({min_score})")

    except (ValueError, TypeError) as e:
        issues.append(f"åˆ†æ•°æ ¼å¼é”™è¯¯: {str(e)}")

    return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜'


def analyze_and_fix(text):
    if pd.isna(text) or not str(text).strip():
        return text, []

    text = normalize_brackets(text)
    text = clean_outer_punctuation(text)
    issues = []

    if text in CUSTOM_WHITELIST:
        return text, []

    # ========== æ‹¬å·æˆå¯¹ä¿®æ­£ ==========
    text_list = list(text)
    stack = []
    unmatched_right = []

    for i, char in enumerate(text_list):
        if char == 'ï¼ˆ':
            stack.append(i)
        elif char == 'ï¼‰':
            if stack:
                stack.pop()
            else:
                unmatched_right.append(i)

    for i in reversed(unmatched_right):
        del text_list[i]
        issues.append("åˆ é™¤å¤šä½™å³æ‹¬å·1ä¸ª")

    if stack:
        text_list.extend(['ï¼‰'] * len(stack))
        issues.append(f"è¡¥å……ç¼ºå¤±å³æ‹¬å·{len(stack)}ä¸ª")

    text = ''.join(text_list)

    # åµŒå¥—ä¿®æ­£
    text, nested_count = NESTED_PAREN_PATTERN.subn(r'ï¼ˆ\1ï¼‰', text)
    if nested_count > 0:
        issues.append(f"ä¿®å¤åµŒå¥—æ‹¬å·{nested_count}å¤„")

    # ========== æ¸…ç†ç©ºæ‹¬å·æˆ–çº¯æ ‡ç‚¹æ‹¬å· ==========
    def clean_empty_paren(m):
        content = m.group(1).strip('ï¼Œã€,;ï¼›:ï¼šã€‚ï¼ï¼Ÿ.!? ')
        if not content:
            issues.append("åˆ é™¤ç©ºæ‹¬å·æˆ–ä»…å«æ ‡ç‚¹æ‹¬å·")
            return ''
        return f'ï¼ˆ{content}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', clean_empty_paren, text)

    # ========== å»é‡ ==========
    seen = set()
    def dedup(m):
        c = m.group(1)
        if c in seen:
            issues.append(f"é‡å¤æ‹¬å·å†…å®¹ï¼š'{c}'")
            return ''
        seen.add(c)
        return f'ï¼ˆ{c}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', dedup, text)

    # ========== å¤šä½™æ ‡ç‚¹ç®€åŒ– ==========
    text = REGEX_PATTERNS['excess_punct'].sub(lambda m: m.group(0)[0], text)

    # ========== é”™åˆ«å­—ä¿®æ­£ ==========
    for typo, corr in TYPO_DICT.items():
        if typo in text:
            text = text.replace(typo, corr)
            issues.append(f"é”™åˆ«å­—ï¼š'{typo}'â†’'{corr}'")

    return text, issues



def process_chunk(chunk):
    """å¤„ç†æ•°æ®å—"""
    # å­¦æ ¡åç§°æ£€æŸ¥
    if 'å­¦æ ¡åç§°' in chunk.columns:
        chunk['å­¦æ ¡åŒ¹é…ç»“æœ'] = chunk['å­¦æ ¡åç§°'].apply(check_school_name)

    # ä¸“ä¸šåŒ¹é…æ£€æŸ¥
    if 'æ‹›ç”Ÿä¸“ä¸š' in chunk.columns and 'ä¸€çº§å±‚æ¬¡' in chunk.columns:
        chunk['æ‹›ç”Ÿä¸“ä¸šåŒ¹é…ç»“æœ'] = chunk.apply(
            lambda r: check_major_combo(r['æ‹›ç”Ÿä¸“ä¸š'], r['ä¸€çº§å±‚æ¬¡']), axis=1)

    # å¤‡æ³¨å¤„ç† - ä¿®æ”¹è¿™éƒ¨åˆ†
    if 'ä¸“ä¸šå¤‡æ³¨' in chunk.columns:
        def process_remark(remark):
            if pd.isna(remark) or not str(remark).strip():
                return 'æ— é—®é¢˜', ''
            fixed_text, issues = analyze_and_fix(remark)
            return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜', fixed_text

        chunk[['å¤‡æ³¨æ£€æŸ¥ç»“æœ', 'ä¿®æ”¹åå¤‡æ³¨']] = chunk['ä¸“ä¸šå¤‡æ³¨'].apply(
            lambda x: pd.Series(process_remark(x)))

    # åˆ†æ•°æ£€æŸ¥
    score_columns = ['æœ€é«˜åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†']
    if all(col in chunk.columns for col in score_columns):
        chunk['åˆ†æ•°æ£€æŸ¥ç»“æœ'] = chunk.apply(check_score_consistency, axis=1)

    # é€‰ç§‘è¦æ±‚å¤„ç†
    if 'é€‰ç§‘è¦æ±‚' in chunk.columns:
        def proc_req(req):
            if pd.isna(req) or not str(req).strip():
                return ["", ""]
            s = str(req).strip()
            if "ä¸é™" in s:
                return ["ä¸é™ç§‘ç›®ä¸“ä¸šç»„", ""]
            if len(s) == 1:
                return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s]
            if "ä¸”" in s:
                return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s.replace("ä¸”", "")]
            if "æˆ–" in s:
                return ["å¤šé—¨é€‰è€ƒ", s.replace("æˆ–", "")]
            return ["", ""]

        chunk[['é€‰ç§‘è¦æ±‚è¯´æ˜', 'æ¬¡é€‰']] = chunk['é€‰ç§‘è¦æ±‚'].apply(
            lambda x: pd.Series(proc_req(x)))

    # æ‹›ç”Ÿç§‘ç±»å¤„ç†
    if 'æ‹›ç”Ÿç§‘ç±»' in chunk.columns:
        chunk['æ‹›ç”Ÿç§‘ç±»'] = chunk['æ‹›ç”Ÿç§‘ç±»'].replace({'ç‰©ç†': 'ç‰©ç†ç±»', 'å†å²': 'å†å²ç±»'})
        chunk['é¦–é€‰ç§‘ç›®'] = chunk['æ‹›ç”Ÿç§‘ç±»'].apply(
            lambda x: str(x)[0] if x in ['ç‰©ç†ç±»', 'å†å²ç±»'] else "")

    return chunk



# ============================
# é™¢æ ¡åˆ†æå–ç›¸å…³å‡½æ•°ï¼ˆæ™®é€šç±»ï¼‰
# ============================
expected_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡',
    'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', 'æ•°æ®æ¥æº',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
]
columns_to_convert = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'
]

def process_score_file(file_path):
    # é¦–å…ˆè¯»å–å¹´ä»½ï¼ˆä»B2å•å…ƒæ ¼ï¼‰
    try:
        wb = openpyxl.load_workbook(file_path, data_only=True)
        ws = wb.active
        year_value = ws['B2'].value
        if year_value is None:
            # å¦‚æœB2ä¸ºç©ºï¼Œå°è¯•ä»æ•°æ®ä¸­æå–å¹´ä»½
            year_value = ''
        else:
            year_value = str(year_value).strip()
        wb.close()
    except Exception as e:
        year_value = ''

    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€é«˜åˆ†': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰': str,
            'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    missing_columns = [col for col in expected_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æœ€é«˜åˆ†'] = pd.to_numeric(df['æœ€é«˜åˆ†'], errors='coerce')
    df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df = df.dropna(subset=['æœ€ä½åˆ†'])

    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'].fillna('')


    # é¦–é€‰ç§‘ç›®è½¬æ¢é€»è¾‘
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()  # å»é™¤å‰åç©ºæ ¼
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',  # ç¡®ä¿å·²ç»æ˜¯"å†å²"çš„ä¸å˜
            'ç‰©ç†': 'ç‰©ç†'  # ç¡®ä¿å·²ç»æ˜¯"ç‰©ç†"çš„ä¸å˜
        })

    try:
        # åˆ¤æ–­æ˜¯å¦æœ‰ä¸“ä¸šç»„ä»£ç åˆ—ï¼Œä¸”ä¸å…¨ä¸ºç©º
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # æ¯ç»„æœ€é«˜åˆ†
        max_scores = df.groupby(group_fields)['æœ€é«˜åˆ†'].max()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

        # è¡¥å……æœ€é«˜åˆ†
        def get_max_score(row):
            key = tuple(row[col] for col in group_fields)
            return max_scores.get(key, None)

        result['æœ€é«˜åˆ†'] = result.apply(get_max_score, axis=1)

        # æ‹›ç”Ÿäººæ•°ã€å½•å–äººæ•°æŒ‰åˆ†ç»„æ€»å’Œ
        enroll_groups = df.groupby(group_fields)['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()
        code_groups = df.groupby(group_fields)['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()

        def get_group_total(row, column_name):
            key = tuple(row[col] for col in group_fields)
            if column_name == 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return enroll_groups.get(key, '')
            elif column_name == 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return code_groups.get(key, '')
            return ''

        result['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)
        result['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # æ„å»ºæ–°çš„æ•°æ®æ¡†ï¼ŒæŒ‰ç…§æ–°çš„åˆ—é¡ºåº
    new_columns = [
        'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§', 
        'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡', 
        'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨', 
        'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç '
    ]
    
    # åˆ›å»ºæ–°çš„DataFrameï¼Œç¡®ä¿æ‰€æœ‰åˆ—éƒ½æœ‰æ­£ç¡®çš„é•¿åº¦
    num_rows = len(result)
    new_result = pd.DataFrame(index=range(num_rows))
    
    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†åˆ—å€¼ï¼Œå°†NaNè½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ï¼ˆç”¨äºæ–‡æœ¬åˆ—ï¼‰
    def get_col_values(col_name, default=''):
        if col_name in result.columns:
            values = result[col_name].fillna(default).astype(str).values
            # å°†'nan'å­—ç¬¦ä¸²è½¬æ¢å›ç©ºå­—ç¬¦ä¸²
            values = ['' if str(v).lower() == 'nan' else v for v in values]
            return values
        else:
            return [default] * num_rows
    
    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†æ•°å­—åˆ—å€¼ï¼Œä¿æŒæ•°å­—ç±»å‹
    def get_numeric_values(col_name, default=0):
        if col_name in result.columns:
            values = result[col_name].fillna(default)
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—ï¼Œæ— æ³•è½¬æ¢çš„ä¿æŒåŸå€¼æˆ–è®¾ä¸ºé»˜è®¤å€¼
            try:
                return pd.to_numeric(values, errors='coerce').fillna(default).values
            except:
                return [default] * num_rows
        else:
            return [default] * num_rows
    
    new_result['å­¦æ ¡åç§°'] = get_col_values('å­¦æ ¡åç§°')
    new_result['çœä»½'] = get_col_values('çœä»½')
    new_result['æ‹›ç”Ÿç±»åˆ«'] = get_col_values('æ‹›ç”Ÿç§‘ç±»')
    new_result['æ‹›ç”Ÿæ‰¹æ¬¡'] = get_col_values('æ‹›ç”Ÿæ‰¹æ¬¡')
    new_result['æ‹›ç”Ÿç±»å‹'] = get_col_values('æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰')
    new_result['é€‰æµ‹ç­‰çº§'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜åˆ†'] = get_col_values('æœ€é«˜åˆ†')
    new_result['æœ€ä½åˆ†'] = get_col_values('æœ€ä½åˆ†')
    new_result['å¹³å‡åˆ†'] = [''] * num_rows  # åˆ é™¤å¹³å‡åˆ†æå–é€»è¾‘ï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€ä½ä½æ¬¡'] = get_col_values('æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰')
    new_result['å¹³å‡ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['å½•å–äººæ•°'] = get_numeric_values('å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ‹›ç”Ÿäººæ•°'] = get_numeric_values('æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ•°æ®æ¥æº'] = get_col_values('æ•°æ®æ¥æº')
    new_result['çœæ§çº¿ç§‘ç±»'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿æ‰¹æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿å¤‡æ³¨'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['ä¸“ä¸šç»„ä»£ç '] = get_col_values('ä¸“ä¸šç»„ä»£ç ')
    new_result['é¦–é€‰ç§‘ç›®'] = get_col_values('é¦–é€‰ç§‘ç›®')
    new_result['é™¢æ ¡æ‹›ç”Ÿä»£ç '] = get_col_values('æ‹›ç”Ÿä»£ç ')

    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        # åˆ›å»ºå¤‡æ³¨æ–‡æœ¬
        remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
    åŒ—äº¬ã€å¤©æ´¥ã€è¾½å®ã€ä¸Šæµ·ã€å±±ä¸œã€å¹¿ä¸œã€æµ·å—é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼ˆæœ€å¤šä¿ç•™2ä½å°æ•°ï¼‰ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
5.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—
6.å½•å–äººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
7.é¦–é€‰ç§‘ç›®ï¼šæ–°å…«çœå¿…å¡«ï¼Œåªèƒ½å¡«å†™ï¼ˆå†å²æˆ–ç‰©ç†ï¼‰"""

        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # å…ˆå†™å…¥æ•°æ®ï¼ˆä¸åŒ…å«æ ‡é¢˜ï¼Œä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            new_result.to_excel(writer, index=False, header=False, startrow=3)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']

            # ç¬¬ä¸€è¡Œï¼šåˆå¹¶A1-U1å¹¶å†™å…¥å¤‡æ³¨
            worksheet.merge_cells('A1:U1')
            worksheet['A1'] = remark_text
            worksheet['A1'].alignment = Alignment(wrap_text=True, vertical='top')
            # è®¾ç½®ç¬¬ä¸€è¡Œè¡Œé«˜ä¸º215ç£…
            worksheet.row_dimensions[1].height = 215
            
            # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´"ï¼ŒB2=å¹´ä»½ï¼ŒC2="1"ï¼ŒD2="æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰"
            worksheet['A2'] = 'æ‹›ç”Ÿå¹´'
            # B2å’ŒC2è®¾ç½®ä¸ºæ•°å­—æ ¼å¼
            try:
                # å°è¯•å°†å¹´ä»½è½¬æ¢ä¸ºæ•°å­—
                if year_value and str(year_value).strip():
                    year_num = int(float(str(year_value).strip()))
                    worksheet['B2'] = year_num
                else:
                    worksheet['B2'] = ''
            except:
                worksheet['B2'] = year_value
            worksheet['C2'] = 1  # ç›´æ¥è®¾ç½®ä¸ºæ•°å­—1
            worksheet['D2'] = 'æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰'
            
            # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œ
            headers = ['å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§', 
                      'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡', 
                      'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨', 
                      'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ']
            for col_idx, header in enumerate(headers, start=1):
                worksheet.cell(row=3, column=col_idx, value=header)

            # è®¾ç½®æ–‡æœ¬æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼Œå³æ•°æ®è¡Œï¼‰
            # éœ€è¦è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼çš„åˆ—ï¼ˆä½¿ç”¨æ–°åˆ—åï¼Œä¸åŒ…æ‹¬æ‹›ç”Ÿäººæ•°å’Œå½•å–äººæ•°ï¼‰
            text_format_cols = ['ä¸“ä¸šç»„ä»£ç ', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½ä½æ¬¡']
            for col in text_format_cols:
                if col in new_result.columns:
                    col_idx = new_result.columns.get_loc(col) + 1
                    for row in range(4, len(new_result) + 4):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT
            
            # ç¡®ä¿B2å’ŒC2å•å…ƒæ ¼ä¿æŒæ•°å­—æ ¼å¼
            if worksheet['B2'].value is not None and str(worksheet['B2'].value).strip():
                try:
                    worksheet['B2'].value = int(float(str(worksheet['B2'].value)))
                except:
                    pass
            worksheet['C2'].value = 1
            
            # ç¡®ä¿"å½•å–äººæ•°"å’Œ"æ‹›ç”Ÿäººæ•°"åˆ—ä¿æŒæ•°å­—æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            if 'å½•å–äººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('å½•å–äººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass
            
            if 'æ‹›ç”Ÿäººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('æ‹›ç”Ÿäººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")

# ============================
# ä¿æŒæ–‡æœ¬æ ¼å¼
# ============================
def process_remarks_file(file_path, progress_callback=None):
    try:
        # è¯»å–æ–‡ä»¶æ—¶ï¼Œç¡®ä¿è¿™äº›å­—æ®µå§‹ç»ˆä»¥å­—ç¬¦ä¸²æ ¼å¼è¯»å–
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
        }, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")
    for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
        if col in df.columns:
            df[col] = df[col].astype(str)
    target_col = None
    for col in df.columns:
        if "ä¸“ä¸šå¤‡æ³¨" in str(col):
            target_col = col
            break
    if not target_col:
        raise Exception("æœªæ‰¾åˆ°'ä¸“ä¸šå¤‡æ³¨'ç›¸å…³åˆ—")
    if target_col != 'ä¸“ä¸šå¤‡æ³¨':
        df = df.rename(columns={target_col: 'ä¸“ä¸šå¤‡æ³¨'})
    chunks = []
    for i in range(0, len(df), 1000):
        chunks.append(df.iloc[i:i + 1000].copy())
    results = {}
    total_chunks = len(chunks)
    with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
        future_to_index = {executor.submit(process_chunk, chunk): idx for idx, chunk in enumerate(chunks)}
        for count, future in enumerate(as_completed(future_to_index)):
            idx = future_to_index[future]
            results[idx] = future.result()
            if progress_callback:
                progress_callback(count + 1, total_chunks)
    ordered_results = [results[i] for i in sorted(results.keys())]
    final_result = pd.concat(ordered_results)
    output_path = file_path.replace('.xlsx', '_æ£€æŸ¥ç»“æœ.xlsx')
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            final_result.to_excel(writer, index=False)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']
            # ä¿æŒæŒ‡å®šåˆ—ä»ç¬¬ä¸‰è¡Œå¼€å§‹æ–‡æœ¬æ ¼å¼
            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in final_result.columns:
                    col_idx = final_result.columns.get_loc(col) + 1  # è½¬æ¢ä¸ºExcelåˆ—å·ï¼ˆA=1ï¼‰
                    # ä»ç¬¬ä¸‰è¡Œå¼€å§‹è®¾ç½®æ ¼å¼ï¼ˆExcelè¡Œå·ä¸º3ï¼Œå¯¹åº”Pythonçš„ç´¢å¼•ä¸º2ï¼‰
                    for row in range(3, len(final_result) + 2):  # å·¥ä½œè¡¨è¡Œå·ä»3å¼€å§‹ï¼ˆç´¢å¼•2ï¼‰
                        cell = worksheet.cell(row=row, column=col_idx)
                        cell.value = final_result.iloc[row - 3][col]  # æ•°æ®ä»ç¬¬ä¸‰è¡Œå¼€å§‹å¡«å……
                        cell.number_format = numbers.FORMAT_TEXT
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–‡ä»¶é”™è¯¯ï¼š{e}")
    return output_path

# ============================
# é™¢æ ¡åˆ†æ•°æ®å¤„ç†ï¼ˆè‰ºä½“ç±»ï¼‰
# ============================

expected_new_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡',
    'ä¸“ä¸šç±»åˆ«', 'æ˜¯å¦æ ¡è€ƒ', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'æ‹›ç”Ÿä»£ç ', 'æ ¡ç»Ÿè€ƒåˆ†',
    'æ ¡æ–‡åŒ–åˆ†', 'ä¸“ä¸šä»£ç ', 'æ•°æ®æ¥æº'
]
columns_to_convert_new = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ ¡ç»Ÿè€ƒåˆ†', 'æ ¡æ–‡åŒ–åˆ†'
]

def process_new_template_file(file_path):
    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ ¡ç»Ÿè€ƒåˆ†': str,
            'æ ¡æ–‡åŒ–åˆ†': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    # æ£€æŸ¥å¿…éœ€åˆ—
    missing_columns = [col for col in expected_new_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    # æ•°å€¼åˆ—è½¬ä¸ºæ•°å€¼å‹
    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æ ¡ç»Ÿè€ƒåˆ†'] = pd.to_numeric(df['æ ¡ç»Ÿè€ƒåˆ†'], errors='coerce')
    df['æ ¡æ–‡åŒ–åˆ†'] = pd.to_numeric(df['æ ¡æ–‡åŒ–åˆ†'], errors='coerce')

    # åˆ é™¤æœ€ä½åˆ†ä¸ºç©ºçš„è¡Œ
    df = df.dropna(subset=['æœ€ä½åˆ†'])
    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    # é¦–é€‰ç§‘ç›®æ¸…æ´—
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',
            'ç‰©ç†': 'ç‰©ç†'
        })

    try:
        # åˆ¤æ–­åˆ†ç»„å­—æ®µ
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # ä¿ç•™æœŸæœ›åˆ—
    selected_columns = [col for col in expected_new_columns if col in result.columns]
    result = result[selected_columns]

    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            result.to_excel(writer, index=False)
            worksheet = writer.sheets['Sheet1']

            # è®¾ç½®æ–‡æœ¬æ ¼å¼
            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in result.columns:
                    col_idx = result.columns.get_loc(col) + 1
                    for row in range(2, len(result) + 2):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT

            for col in columns_to_convert_new:
                if col in result.columns and col not in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                    col_idx = result.columns.get_loc(col) + 1
                    for cell in list(worksheet.iter_cols(min_col=col_idx, max_col=col_idx, min_row=2, values_only=False))[0]:
                        cell.number_format = numbers.FORMAT_TEXT

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")



# ============================
# ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†
# ============================

def process_segmentation_file(file_path):
    output_path = os.path.splitext(file_path)[0] + "_æ ¡éªŒç»“æœ.xlsx"
    wb = openpyxl.load_workbook(file_path)
    ws = wb.active

    ws['E7'] = 'ç´¯è®¡äººæ•°æ ¡éªŒç»“æœ'
    ws['F7'] = 'åˆ†æ•°æ ¡éªŒç»“æœ'
    ws['F2'] = 'å¹´ä»½æ ¡éªŒ'

    # æ ¡éªŒ B2 æ˜¯å¦ä¸º 2025
    if ws['B2'].value != 2025:
        ws['G2'] = f"Ã— åº”ä¸º2025ï¼Œå½“å‰ä¸ºï¼š{ws['B2'].value}"
    else:
        ws['G2'] = "âˆš"

    region = ws['B3'].value
    suffix = "-750"
    if region == "ä¸Šæµ·":
        suffix = "-660"
    elif region == "æµ·å—":
        suffix = "-900"

    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    # ---------- ç¬¬8è¡Œç‰¹æ®Šå¤„ç† ----------
    row = 8
    curr_score = ws[f"A{row}"].value
    curr_num = ws[f"B{row}"].value
    curr_total = ws[f"C{row}"].value

    try:
        score_int = int(float(str(curr_score).split('-')[0]))
    except:
        score_int = None

    inserted = False
    if curr_total is not None:
        if curr_num is None or curr_num == "":
            # æ²¡æœ‰äººæ•° â†’ è‡ªåŠ¨è®¡ç®—
            if row == 8:
                ws[f"B{row}"] = curr_total
            else:
                prev_total = ws[f"C{row - 1}"].value
                if prev_total is not None:
                    ws[f"B{row}"] = curr_total - prev_total
        else:
            # æœ‰äººæ•°å’Œç´¯è®¡äººæ•°ä¸ä¸€è‡´æ—¶æ’å…¥è¡¥æ–­ç‚¹è¡Œ
            if curr_num != curr_total:
                try:
                    insert_score = score_int + 1
                    insert_num = curr_total - curr_num
                    ws.insert_rows(row)
                    ws[f"A{row}"] = f"{insert_score}{suffix}"  # âœ… ä»…åŠ åç¼€åœ¨æ–°å¢è¡Œ
                    ws[f"B{row}"] = insert_num
                    ws[f"C{row}"] = insert_num
                    for col in ['A', 'B', 'C', 'E', 'F']:
                        ws[f"{col}{row}"].fill = yellow_fill
                    ws[f"E{row}"] = "è¡¥æ–­ç‚¹"
                    ws[f"F{row}"] = "è¡¥æ–­ç‚¹"
                    inserted = True
                except:
                    pass

    # ä»…å½“æ²¡æœ‰æ’å…¥è¡Œæ—¶ï¼Œç¬¬8è¡ŒåŠ åç¼€
    if not inserted and score_int is not None:
        ws[f"A{row}"] = f"{score_int}{suffix}"

    # ---------- è¡¥æ–­ç‚¹é€»è¾‘ ----------
    while row < ws.max_row:
        curr = ws[f"A{row}"].value
        next = ws[f"A{row + 1}"].value
        try:
            curr_score_int = int(str(curr).split('-')[0])
            next_score_int = int(str(next).split('-')[0])
        except:
            row += 1
            continue

        if curr_score_int - next_score_int > 1:
            missing_score = curr_score_int - 1
            ws.insert_rows(row + 1)
            ws[f"A{row + 1}"] = missing_score
            ws[f"B{row + 1}"] = 0
            ws[f"C{row + 1}"] = ws[f"C{row}"].value
            for col in ['A', 'B', 'C', 'E', 'F']:
                ws[f"{col}{row + 1}"].fill = yellow_fill
            ws[f"E{row + 1}"] = "è¡¥æ–­ç‚¹"
            ws[f"F{row + 1}"] = "è¡¥æ–­ç‚¹"
        else:
            row += 1

    # ---------- æ ¡éªŒä¸è‡ªåŠ¨è¡¥äººæ•° ----------
    for row in range(8, ws.max_row + 1):
        curr_score = ws[f"A{row}"].value
        curr_num = ws[f"B{row}"].value
        curr_total = ws[f"C{row}"].value
        prev_total = ws[f"C{row - 1}"].value if row > 8 else None
        prev_score = ws[f"A{row - 1}"].value if row > 8 else None

        # è‡ªåŠ¨è¡¥äººæ•°
        if (curr_num is None or curr_num == "") and curr_total is not None:
            if row == 8:
                ws[f"B{row}"] = curr_total
                curr_num = curr_total
            elif prev_total is not None:
                try:
                    calc = curr_total - prev_total
                    ws[f"B{row}"] = calc
                    curr_num = calc
                except:
                    pass

        # æ ¡éªŒç´¯è®¡äººæ•°
        if row == 8:
            # ç¬¬8è¡Œç›´æ¥æ ‡è®°æ­£ç¡®ï¼ˆå‡è®¾ç¬¬8è¡Œç´¯è®¡äººæ•°æ­£ç¡®ï¼‰
            if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"E{row}"] = "âˆš"
            correct_total = curr_total
        else:
            if curr_num is not None and curr_total is not None and correct_total is not None:
                expected_total = correct_total + curr_num
                if expected_total == curr_total:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = "âˆš"
                    correct_total = curr_total  # æœ¬è¡Œç´¯è®¡æ­£ç¡®ï¼Œç”¨å®ƒæ›´æ–°åŸºå‡†
                else:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = f"Ã— åº”ä¸º{expected_total}"
                    correct_total = expected_total

        # æ ¡éªŒåˆ†æ•°å·®
        try:
            curr_score_num = float(str(curr_score).split('-')[0])
            prev_score_num = float(str(prev_score).split('-')[0])
        except:
            curr_score_num = prev_score_num = None

        if curr_score_num is not None and prev_score_num is not None:
            diff = prev_score_num - curr_score_num
            if diff == 1:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = "âˆš"
            else:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = f"Ã— å·®å€¼{diff}"
        else:
            if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"F{row}"] = "Ã— åˆ†æ•°éæ•°å­—ï¼Œæ— æ³•æ ¡éªŒ"

    wb.save(output_path)
    return output_path




# ============================
# ä¸“ä¸šç»„ä»£ç åŒ¹é…
# ============================

tableA_fields = [
    "å­¦æ ¡åç§°", "çœä»½", "æ‹›ç”Ÿä¸“ä¸š", "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰",
    "ä¸€çº§å±‚æ¬¡", "æ‹›ç”Ÿç§‘ç±»", "æ‹›ç”Ÿæ‰¹æ¬¡", "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰"
]

rename_mapping_B = {
    "å­¦æ ¡": "å­¦æ ¡åç§°",
    "çœä»½": "çœä»½",
    "å±‚æ¬¡": "ä¸€çº§å±‚æ¬¡",
    "ç§‘ç±»": "æ‹›ç”Ÿç§‘ç±»",
    "æ‰¹æ¬¡": "æ‹›ç”Ÿæ‰¹æ¬¡",
    "æ‹›ç”Ÿç±»å‹": "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰",
    "ä¸“ä¸š": "æ‹›ç”Ÿä¸“ä¸š",
    "å¤‡æ³¨": "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"
}


def process_data(dfA, dfB):
    dfB.rename(columns=rename_mapping_B, inplace=True)

    # æ„å»ºç»„åˆé”®ï¼ˆä¸å«å¤‡æ³¨ï¼‰ï¼šå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-æ‹›ç”Ÿç±»å‹-ä¸“ä¸š
    key_fields = [f for f in tableA_fields if f != "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"]
    dfA["ç»„åˆé”®"] = dfA[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)
    dfB["ç»„åˆé”®"] = dfB[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)

    # æ£€æŸ¥Aè¡¨å’ŒBè¡¨ä¸­ç»„åˆé”®çš„é‡å¤æ€§
    # ç»Ÿè®¡Aè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    a_key_counts = dfA["ç»„åˆé”®"].value_counts()
    # ç»Ÿè®¡Bè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    b_key_counts = dfB["ç»„åˆé”®"].value_counts()
    
    # æ‰¾å‡ºAè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    a_duplicate_keys = set(a_key_counts[a_key_counts > 1].index)
    # æ‰¾å‡ºBè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    b_duplicate_keys = set(b_key_counts[b_key_counts > 1].index)

    # æ„å»ºBè¡¨å­—å…¸ï¼šç»„åˆé”® â†’ è®°å½•åˆ—è¡¨
    b_dict = dfB.groupby("ç»„åˆé”®").apply(lambda x: x.to_dict("records")).to_dict()

    def get_code(row):
        key = row["ç»„åˆé”®"]
        candidates = b_dict.get(key, [])

        # æƒ…å†µ1ï¼šæ— å€™é€‰è®°å½•
        if not candidates:
            return None

        # æ£€æŸ¥è¯¥ç»„åˆé”®åœ¨Aè¡¨æˆ–Bè¡¨ä¸­æ˜¯å¦æœ‰é‡å¤
        has_duplicate_in_a = key in a_duplicate_keys
        has_duplicate_in_b = key in b_duplicate_keys

        # å¦‚æœAè¡¨æˆ–Bè¡¨ä¸­ä»»ä½•ä¸€ä¸ªæœ‰é‡å¤ï¼Œä¸èƒ½æŒ‰è¿™å‡ ä¸ªå­—æ®µç›´æ¥åŒ¹é…ï¼Œè¿”å›None
        if has_duplicate_in_a or has_duplicate_in_b:
            return None

        # Aè¡¨å’ŒBè¡¨ä¸­éƒ½æ²¡æœ‰é‡å¤ï¼Œä¸”Bè¡¨ä¸­åªæœ‰å”¯ä¸€å€™é€‰è®°å½•ï¼Œå¯ä»¥ç›´æ¥åŒ¹é…
        if len(candidates) == 1:
            return candidates[0]["ä¸“ä¸šç»„ä»£ç "]

        # å¦‚æœBè¡¨ä¸­æœ‰å¤šä¸ªå€™é€‰è®°å½•ï¼ˆè¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‡ºç°ï¼Œå› ä¸ºBè¡¨æ²¡æœ‰é‡å¤ï¼‰ï¼Œè¿”å›None
        return None

    dfA["ä¸“ä¸šç»„ä»£ç "] = dfA.apply(get_code, axis=1)

    return dfA


 # ========== å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå– ==========
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from PIL import Image
import io

def fetch_images_static(url, output_folder):
    os.makedirs(output_folder, exist_ok=True)
    image_paths = []
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        imgs = soup.find_all("img")
        for idx, img in enumerate(imgs, 1):
            src = img.get("src")
            if not src:
                continue
            full_url = urljoin(url, src)
            # è·³è¿‡ base64 æˆ– blob ç±»å‹
            if full_url.startswith("data:") or full_url.startswith("blob:"):
                continue
            ext = os.path.splitext(urlparse(full_url).path)[1] or ".jpg"
            filename = f"img_{idx:03d}{ext}"
            path = os.path.join(output_folder, filename)
            try:
                img_resp = requests.get(full_url, timeout=10)
                if img_resp.status_code != 200:
                    continue
                content_type = img_resp.headers.get("content-type", "")
                # ä»…ä¿å­˜çœŸæ­£çš„å›¾ç‰‡ç±»å‹
                if not content_type.startswith("image/"):
                    continue
                img_data = img_resp.content
                # éªŒè¯å›¾ç‰‡æ˜¯å¦å¯è¯†åˆ«
                try:
                    Image.open(io.BytesIO(img_data))
                except Exception:
                    continue
                with open(path, "wb") as f:
                    f.write(img_data)
                image_paths.append(path)
            except Exception:
                continue
    except Exception as e:
        raise Exception(f"é™æ€æ¨¡å¼åŠ è½½å¤±è´¥: {e}")
    return image_paths


def images_to_pdf(image_paths, pdf_path):
    images = []
    for path in sorted(image_paths):
        try:
            img = Image.open(path).convert("RGB")
            images.append(img)
        except Exception:
            continue
    if images:
        images[0].save(pdf_path, save_all=True, append_images=images[1:])
        return True
    return False




# ============================
# Streamlité¡µé¢å¸ƒå±€
# ============================
# é¡µé¢æ ‡é¢˜
st.title("ğŸ“Š æ•°æ®å¤„ç†å·¥å…·")
st.markdown("---")

# åŠŸèƒ½è¯´æ˜
with st.expander("ğŸ“Œ åŠŸèƒ½è¯´æ˜", expanded=True):
    st.markdown("""
    1. ä¸Šä¼ çš„æ–‡ä»¶ä½¿ç”¨åº“ä¸­ä¸“ä¸šåˆ†ã€é™¢æ ¡åˆ†ã€æ‹›ç”Ÿè®¡åˆ’ã€ä¸€åˆ†ä¸€æ®µçš„æ¨¡æ¿ï¼Œç›´æ¥ä¸Šä¼ å³å¯ï¼Œæ— éœ€åˆ å‡
    2. å¤‡æ³¨æ£€æŸ¥ä¸­ï¼Œæ£€æŸ¥å‡ºæ¥æ‹¬å·æœ‰é—®é¢˜çš„å†…å®¹è¿˜éœ€è¦è‡ªå·±å†è¿‡ä¸€éï¼›æ•´ä¸ªæ–‡ä»¶çš„å¤‡æ³¨éœ€è¦å¤§æ¦‚çœ‹çœ‹æœ‰æ²¡æœ‰é”™åˆ«å­—
    3. æ ¡éªŒä¸€åˆ†ä¸€æ®µæ—¶ï¼Œå†…å®¹ä¸èƒ½ä¸ºæ–‡æœ¬æ ¼å¼
    4. ä½¿ç”¨ä¸“ä¸šç»„ä»£ç åŒ¹é…æ—¶ï¼Œä¸¤ä»½æ–‡ä»¶ä¸­çš„â€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹â€è¿™äº›å­—æ®µéœ€è¦ä¿æŒä¸€è‡´
    """)

# æ›´æ–°æ—¥å¿—å¯¹è¯æ¡†
with st.expander("ğŸ“¢ ç‰ˆæœ¬æ›´æ–°ï¼ˆ2025.9.26æ›´æ–°ï¼‰ï¼ˆå¿…çœ‹ï¼ï¼‰", expanded=False):
    st.markdown("""
    ### 2025.9.26æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†ä¸­æœ€é«˜åˆ†çš„æå–é€»è¾‘  
    â€¢ æ–°å¢äº†è‰ºä½“ç±»é™¢æ ¡åˆ†æå–åŠŸèƒ½ï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ è‰ºä½“ç±»ä¸“ä¸šåˆ†æ¨¡æ¿ï¼ˆå¯æŠŠç‰¹æ®Šç±»å‹<å¦‚ï¼šä¸­å¤–åˆä½œåŠå­¦>çš„å¤‡æ³¨åœ¨ä¸“ä¸šåˆ†ä¸­æ”¾åˆ°ä¸“ä¸šæ–¹å‘å†æå–ï¼‰

    ### å†å²æ›´æ–°

    #### 2025.4.14æ›´æ–°
    â€¢ æ‹›ç”Ÿä»£ç å’Œä¸“ä¸šä»£ç ä¿æŒæ–‡æœ¬æ ¼å¼  
    â€¢ å¢åŠ åŠŸèƒ½è¯´æ˜  
    â€¢ ä¼˜åŒ–å·¥å…·ç•Œé¢  

    #### 2025.4.16æ›´æ–°
    â€¢ ä¼˜åŒ–äº†é™¢æ ¡åˆ†æå–å¤„ç†é€»è¾‘  

    #### 2025.5.22æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†æå–ä¸­å½•å–äººæ•°çš„å¤„ç†é€»è¾‘ï¼ˆå»ºè®®è¿›è¡ŒæŠ½æŸ¥ï¼‰  
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†æœ€é«˜åˆ†ã€å¹³å‡åˆ†ã€æœ€ä½åˆ†çš„æ ¡éªŒï¼Œä¼šåœ¨æœ€ååŠ ä¸€åˆ—æ ¡éªŒç»“æœ  

    #### 2025.5.23æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†å­¦æ ¡åç§°å’Œæ‹›ç”Ÿä¸“ä¸šçš„åŒ¹é…  

    #### 2025.5.27æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­ï¼Œå¢åŠ äº†"æ‹›ç”Ÿç§‘ç±»"ã€"é¦–é€‰ç§‘ç›®"ã€"é€‰ç§‘è¦æ±‚"ï¼Œ"æ¬¡é€‰ç§‘ç›®"çš„å¤„ç†  
      - å­¦ä¸šæ¡¥æä¾›çš„"3+1+2"çœä»½çš„æ‹›ç”Ÿç§‘ç±»ä¸º"ç‰©ç†"ã€"å†å²"ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†çš„"ç‰©ç†ç±»"ã€"å†å²ç±»"  
      - "3+1+2"çœä»½çš„é¦–é€‰ç§‘ç›®å¯ä»¥ç›´æ¥æ ¹æ®æ‹›ç”Ÿç§‘ç±»æå–  
      - æ–°å¢äº†é€‰ç§‘è¦æ±‚ã€æ¬¡é€‰ç§‘ç›®çš„å¤„ç†ï¼Œå¯ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†ï¼ˆå¤„ç†åçš„æ•°æ®åœ¨æ–‡æ¡£æœ€åå‡ åˆ—ï¼‰  

    #### 2025.5.30æ›´æ–°
    æ–°å¢"ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"  
      - å¯ç›´æ¥æ ¡éªŒåˆ†æ•°ã€ç´¯è®¡äººæ•°  
      - è‡ªåŠ¨è¡¥æ–­ç‚¹  
      - è‡ªåŠ¨å¢åŠ "æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  

    ### 2025.6.6æ›´æ–°
    "ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"ä¼˜åŒ–  
      - è‡ªåŠ¨è¡¥å……"æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  
      - åªæœ‰ç´¯è®¡äººæ•°æ²¡æœ‰äººæ•°æ—¶ï¼Œå¯è®¡ç®—äººæ•°ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ  
      - è¡¥æ–­ç‚¹çš„åˆ†æ•°æ ‡æ³¨é¢œè‰²ï¼Œå¹¶åœ¨åˆ†æ•°å’Œäººæ•°æ ¡éªŒä¸­æ ‡æ³¨"è¡¥æ–­ç‚¹"

    ### 2025.6.12æ›´æ–°
    é™¢æ ¡åˆ†æå–é€»è¾‘æ›´æ–°  
      - æå–æœ€é«˜åˆ†æ”¹ä¸ºå–åŒä¸€ä¸ªâ€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹ï¼ˆ-ä¸“ä¸šç»„ä»£ç ï¼‰â€ä¸‹çš„æœ€é«˜åˆ†
      
    ### 2025.6.14æ›´æ–°
    ä¸“ä¸šç»„ä»£ç åŒ¹é…åŠŸèƒ½  
      - éœ€è¦ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿å’Œåº“ä¸­æ‹›ç”Ÿè®¡åˆ’å¯¼å‡ºæ¨¡æ¿
      - æŠŠåº“ä¸­å¯¼å‡ºæ‹›ç”Ÿè®¡åˆ’ç±»å‹å°½é‡è¡¥å……å®Œæ•´ï¼Œå¦åˆ™å®¹æ˜“å‡ºé”™
      - åŒ¹é…ç»“æœéœ€è¦æ£€æŸ¥
      
    ### 2025.7.7æ›´æ–°
    å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æŠ“å–åŠŸèƒ½  
      - æŠ“å–å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡
      - å¦‚æœæŠ“å–åˆ°çš„å›¾ç‰‡æ¯”è¾ƒå¤šï¼Œâ€œä¸‹è½½PDFâ€çš„å¼¹æ¡†ä¼šå‡ºç°æ¯”è¾ƒæ…¢
      - æ³¨æ„ï¼šåªèƒ½æŠ“å–é™æ€é¡µé¢çš„å›¾ç‰‡ï¼ŒåŠ¨æ€é¡µé¢å’Œæœ‰é™åˆ¶çš„ç½‘é¡µæ— æ³•æŠ“å–
    

    """)

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
    [
        "é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰",
        "é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰",
        "å­¦ä¸šæ¡¥æ•°æ®å¤„ç†",
        "ä¸€åˆ†ä¸€æ®µæ ¡éªŒ",
        "ä¸“ä¸šç»„ä»£ç åŒ¹é…ï¼ˆå¯ä»¥ç”¨ï¼Œéœ€è¦æ£€æŸ¥ï¼ï¼‰",
        "å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–",
        "æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ï¼ˆHTMLå·¥å…·ï¼‰"
    ]
)


# ====================== é™¢æ ¡åˆ†æå– ======================
with tab1:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="score_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_score_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_score_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰ ======================
with tab2:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file_new = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="new_score_file")

    if uploaded_file_new is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file_new.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_new_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_new_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file_new.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # è°ƒç”¨æ–°æ¨¡æ¿å¤„ç†å‡½æ•°
                    if percent_complete == 100:
                        output_path = process_new_template_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†ï¼ˆè‰ºä½“ç±»ï¼‰æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")



# ====================== å­¦ä¸šæ¡¥æ•°æ®å¤„ç† ======================
with tab3:
    st.header("å­¦ä¸šæ¡¥æ•°æ®å¤„ç†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="remarks_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_remarks"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_remarks.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())


                # è¿›åº¦å›è°ƒå‡½æ•°
                def update_progress(current, total):
                    percent = int((current / total) * 100)
                    progress_bar.progress(percent)
                    status_text.text(f"å¤„ç†ä¸­... {percent}%")


                # å¤„ç†æ–‡ä»¶
                output_path = process_remarks_file(temp_file, progress_callback=update_progress)

                # å¤„ç†å®Œæˆ
                progress_bar.progress(100)
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸€åˆ†ä¸€æ®µæ ¡éªŒ ======================
with tab4:
    st.header("ä¸€åˆ†ä¸€æ®µæ ¡éªŒ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="segmentation_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_segmentation"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "ä¸€åˆ†ä¸€æ®µ.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_segmentation_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_segmentation_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()

                b64 = base64.b64encode(bytes_data).decode()

                # ä» output_path æå–åŸæ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
                base_name = os.path.splitext(os.path.basename(output_path))[0]

                # æ‹¼æ¥æ–°æ–‡ä»¶å
                new_filename = f"{base_name}.xlsx"

                # æ„é€ ä¸‹è½½é“¾æ¥
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="{new_filename}">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'

                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸“ä¸šç»„ä»£ç åŒ¹é… ======================
with tab5:
    st.header("ä¸“ä¸šç»„ä»£ç åŒ¹é…ï¼ˆéœ€è¦æ£€æŸ¥ï¼ï¼‰")

    uploaded_fileA = st.file_uploader("ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿", type=["xls", "xlsx"], key="fileA")
    uploaded_fileB = st.file_uploader("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ•°æ®å¯¼å‡ºæ–‡ä»¶", type=["xls", "xlsx"], key="fileB")

    if uploaded_fileA and uploaded_fileB:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶ï¼š{uploaded_fileA.name} å’Œ {uploaded_fileB.name}")

        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("ç­‰å¾…å¼€å§‹å¤„ç†...")

        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="start_match"):
            try:
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                temp_fileA = "tempA.xlsx"
                temp_fileB = "tempB.xlsx"
                with open(temp_fileA, "wb") as f:
                    f.write(uploaded_fileA.getbuffer())
                with open(temp_fileB, "wb") as f:
                    f.write(uploaded_fileB.getbuffer())

                status_text.text("è¯»å–æ–‡ä»¶...")
                progress_bar.progress(10)

                dfA = pd.read_excel(temp_fileA, header=2)
                dfB = pd.read_excel(temp_fileB)

                status_text.text("å¼€å§‹å¤„ç†æ•°æ®...")
                for percent_complete in range(20, 101, 20):
                    progress_bar.progress(percent_complete)
                    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥å»æ‰
                    # time.sleep(0.2)

                result_df = process_data(dfA, dfB)

                status_text.text("å¤„ç†å®Œæˆï¼å‡†å¤‡å¯¼å‡º...")
                progress_bar.progress(100)

                # å¯¼å‡ºç»“æœåˆ°å†…å­˜
                output = BytesIO()
                result_df.to_excel(output, index=False)
                output.seek(0)

                b64 = base64.b64encode(output.read()).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="ä¸“ä¸šç»„ä»£ç åŒ¹é…ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½åŒ¹é…ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_fileA)
                os.remove(temp_fileB)

                status_text.text("å·²å®Œæˆï¼Œç»“æœå¯ä¸‹è½½ã€‚")
                st.balloons()

            except Exception as e:
                st.error(f"å¤„ç†é”™è¯¯ï¼š{e}")
    else:
        st.info("è¯·å…ˆä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶")

# ====================== tab5ï¼šç½‘é¡µå›¾ç‰‡æå–PDF ======================
with tab6:
    st.header("å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–")

    url = st.text_input("è¯·è¾“å…¥å°±ä¸šè´¨é‡æŠ¥å‘Šç½‘é¡µé“¾æ¥", placeholder="ä¾‹å¦‚ï¼šhttps://www.example.com/report.html")

    if st.button("å¼€å§‹æå–å›¾ç‰‡"):
        if not url:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘é¡µé“¾æ¥")
        else:
            output_folder = tempfile.mkdtemp()
            with st.spinner("æ­£åœ¨æŠ“å–å›¾ç‰‡..."):
                try:
                    image_paths = fetch_images_static(url, output_folder)
                except Exception as e:
                    st.error(f"æŠ“å–å¤±è´¥: {e}")
                    image_paths = []

            if image_paths:
                st.success(f"æˆåŠŸæå–åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

                with st.expander(f"ç‚¹å‡»æŸ¥çœ‹ {len(image_paths)} å¼ å›¾ç‰‡é¢„è§ˆ", expanded=False):
                    cols = st.columns(5)
                    for i, path in enumerate(image_paths):
                        cols[i % 5].image(path, width=120)

                pdf_path = os.path.join(output_folder, "å›¾ç‰‡åˆé›†.pdf")
                if images_to_pdf(image_paths, pdf_path):
                    with open(pdf_path, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è½½åˆæˆPDF", f, file_name="å°±ä¸šè´¨é‡æŠ¥å‘Š.pdf", mime="application/pdf")
                else:
                    st.warning("PDFåˆæˆå¤±è´¥")
            else:
                st.warning("æœªæŠ“å–åˆ°ä»»ä½•å›¾ç‰‡")

# ====================== æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹åŠŸèƒ½å‡½æ•° ======================

# ========== æ•°æ®åŠ è½½å‡½æ•° ==========
def load_excel_from_bytes_plan(file_bytes):
    """ä»å­—èŠ‚æµåŠ è½½Excelæ–‡ä»¶"""
    try:
        df = pd.read_excel(BytesIO(file_bytes), sheet_name=0)
        logging.info(f"æˆåŠŸåŠ è½½æ–‡ä»¶ï¼Œå…± {len(df)} æ¡è®°å½•ï¼Œ{len(df.columns)} åˆ—")
        return df
    except Exception as e:
        logging.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
        raise


# ========== å…³é”®å­—ç”Ÿæˆå‡½æ•° ==========
def generate_plan_score_key(row):
    """ç”Ÿæˆæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†çš„æ¯”å¯¹å…³é”®å­—"""
    try:
        key_parts = [
            str(row.get('å¹´ä»½', '')).strip(),
            str(row.get('çœä»½', '')).strip(),
            str(row.get('å­¦æ ¡', '')).strip(),
            str(row.get('ç§‘ç±»', '')).strip(),
            str(row.get('æ‰¹æ¬¡', '')).strip(),
            str(row.get('ä¸“ä¸š', '')).strip(),
            str(row.get('å±‚æ¬¡', '')).strip(),
            str(row.get('ä¸“ä¸šç»„ä»£ç ', '')).strip()
        ]
        return '|'.join(key_parts)
    except Exception as e:
        logging.error(f"ç”Ÿæˆå…³é”®å­—å¤±è´¥: {e}")
        return '|'.join([''] * 8)


def generate_plan_college_key(row):
    """ç”Ÿæˆæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†çš„æ¯”å¯¹å…³é”®å­—"""
    try:
        key_parts = [
            str(row.get('å¹´ä»½', '')).strip(),
            str(row.get('çœä»½', '')).strip(),
            str(row.get('å­¦æ ¡', '')).strip(),
            str(row.get('ç§‘ç±»', '')).strip(),
            str(row.get('æ‰¹æ¬¡', '')).strip(),
            str(row.get('ä¸“ä¸šç»„ä»£ç ', '')).strip()
        ]
        return '|'.join(key_parts)
    except Exception as e:
        logging.error(f"ç”Ÿæˆå…³é”®å­—å¤±è´¥: {e}")
        return '|'.join([''] * 6)


# ========== æ•°æ®æ¯”å¯¹å‡½æ•° ==========
def compare_plan_vs_score_func(plan_df, score_df):
    """æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†"""
    results = []
    
    score_keys = set()
    for idx, row in score_df.iterrows():
        key = generate_plan_score_key(row)
        score_keys.add(key)
    
    logging.info(f"ä¸“ä¸šåˆ†å…³é”®å­—æ•°: {len(score_keys)}")
    
    for idx, row in plan_df.iterrows():
        key = generate_plan_score_key(row)
        exists = key in score_keys
        
        result = {
            'index': idx + 1,
            'original_index': idx,
            'key_fields': {
                'å¹´ä»½': row.get('å¹´ä»½', ''),
                'çœä»½': row.get('çœä»½', ''),
                'å­¦æ ¡': row.get('å­¦æ ¡', ''),
                'ç§‘ç±»': row.get('ç§‘ç±»', ''),
                'æ‰¹æ¬¡': row.get('æ‰¹æ¬¡', ''),
                'ä¸“ä¸š': row.get('ä¸“ä¸š', ''),
                'å±‚æ¬¡': row.get('å±‚æ¬¡', ''),
                'ä¸“ä¸šç»„ä»£ç ': row.get('ä¸“ä¸šç»„ä»£ç ', '')
            },
            'exists': exists,
            'other_info': {
                'æ‹›ç”Ÿäººæ•°': row.get('æ‹›ç”Ÿäººæ•°', ''),
                'å­¦è´¹': row.get('å­¦è´¹', ''),
                'å­¦åˆ¶': row.get('å­¦åˆ¶', ''),
                'ä¸“ä¸šä»£ç ': row.get('ä¸“ä¸šä»£ç ', ''),
                'æ‹›ç”Ÿä»£ç ': row.get('æ‹›ç”Ÿä»£ç ', ''),
                'æ•°æ®æ¥æº': row.get('æ•°æ®æ¥æº', ''),
                'å¤‡æ³¨': row.get('å¤‡æ³¨', ''),
                'æ‹›ç”Ÿç±»å‹': row.get('æ‹›ç”Ÿç±»å‹', ''),
                'ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚': row.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', ''),
                'ä¸“ä¸šé€‰ç§‘è¦æ±‚': row.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '')
            },
            'raw_data': row
        }
        results.append(result)
    
    logging.info(f"æ¯”å¯¹1å®Œæˆ: æ€»è®°å½• {len(plan_df)}, åŒ¹é… {sum(1 for r in results if r['exists'])}, "
                f"æœªåŒ¹é… {sum(1 for r in results if not r['exists'])}")
    
    return results


def compare_plan_vs_college_func(plan_df, college_df):
    """æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†"""
    results = []
    
    college_keys = set()
    for idx, row in college_df.iterrows():
        key = generate_plan_college_key(row)
        college_keys.add(key)
    
    logging.info(f"é™¢æ ¡åˆ†å…³é”®å­—æ•°: {len(college_keys)}")
    
    for idx, row in plan_df.iterrows():
        key = generate_plan_college_key(row)
        exists = key in college_keys
        
        result = {
            'index': idx + 1,
            'original_index': idx,
            'key_fields': {
                'å¹´ä»½': row.get('å¹´ä»½', ''),
                'çœä»½': row.get('çœä»½', ''),
                'å­¦æ ¡': row.get('å­¦æ ¡', ''),
                'ç§‘ç±»': row.get('ç§‘ç±»', ''),
                'æ‰¹æ¬¡': row.get('æ‰¹æ¬¡', ''),
                'ä¸“ä¸šç»„ä»£ç ': row.get('ä¸“ä¸šç»„ä»£ç ', '')
            },
            'exists': exists,
            'other_info': {
                'ä¸“ä¸š': row.get('ä¸“ä¸š', ''),
                'å±‚æ¬¡': row.get('å±‚æ¬¡', ''),
                'æ‹›ç”Ÿäººæ•°': row.get('æ‹›ç”Ÿäººæ•°', ''),
                'å­¦è´¹': row.get('å­¦è´¹', ''),
                'å­¦åˆ¶': row.get('å­¦åˆ¶', ''),
                'ä¸“ä¸šä»£ç ': row.get('ä¸“ä¸šä»£ç ', ''),
                'æ‹›ç”Ÿä»£ç ': row.get('æ‹›ç”Ÿä»£ç ', ''),
                'æ•°æ®æ¥æº': row.get('æ•°æ®æ¥æº', ''),
                'å¤‡æ³¨': row.get('å¤‡æ³¨', ''),
                'æ‹›ç”Ÿç±»å‹': row.get('æ‹›ç”Ÿç±»å‹', ''),
                'ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚': row.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', ''),
                'ä¸“ä¸šé€‰ç§‘è¦æ±‚': row.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '')
            },
            'raw_data': row
        }
        results.append(result)
    
    logging.info(f"æ¯”å¯¹2å®Œæˆ: æ€»è®°å½• {len(plan_df)}, åŒ¹é… {sum(1 for r in results if r['exists'])}, "
                f"æœªåŒ¹é… {sum(1 for r in results if not r['exists'])}")
    
    return results


# ========== ç»Ÿè®¡å‡½æ•° ==========
def get_comparison_stats_plan(results):
    """è·å–æ¯”å¯¹ç»“æœç»Ÿè®¡ä¿¡æ¯"""
    total = len(results)
    matched = sum(1 for r in results if r['exists'])
    unmatched = total - matched
    match_rate = (matched / total * 100) if total > 0 else 0
    
    return {
        'total': total,
        'matched': matched,
        'unmatched': unmatched,
        'match_rate': f"{match_rate:.2f}%"
    }


def get_unique_provinces_plan(results):
    """ä»æ¯”å¯¹ç»“æœä¸­æå–å”¯ä¸€çš„çœä»½åˆ—è¡¨"""
    provinces = set()
    for result in results:
        province = result['key_fields'].get('çœä»½', '')
        if province:
            provinces.add(str(province).strip())
    return sorted(list(provinces))


def get_unique_batches_plan(results):
    """ä»æ¯”å¯¹ç»“æœä¸­æå–å”¯ä¸€çš„æ‰¹æ¬¡åˆ—è¡¨"""
    batches = set()
    for result in results:
        batch = result['key_fields'].get('æ‰¹æ¬¡', '')
        if batch:
            batches.add(str(batch).strip())
    return sorted(list(batches))


# ========== æ•°æ®è½¬æ¢å‡½æ•° ==========
def get_first_subject_plan(category):
    """è·å–é¦–é€‰ç§‘ç›®"""
    category_str = str(category).strip()
    if not category_str:
        return ''
    first_char = category_str[0]
    subject_map = {
        'ç‰©': 'ç‰©',
        'å†': 'å†',
        'æ–‡': 'æ–‡',
        'ç†': 'ç†',
        'ç»¼': 'ç»¼'
    }
    return subject_map.get(first_char, first_char)


def convert_level_plan(level):
    """è½¬æ¢å±‚æ¬¡å­—æ®µ"""
    level_str = str(level).strip().lower()
    
    conversion_map = {
        'æœ¬ç§‘': 'æœ¬ç§‘',
        'undergraduate': 'æœ¬ç§‘',
        'ä¸“ç§‘': 'ä¸“ç§‘ï¼ˆé«˜èŒï¼‰',
        'vocational': 'ä¸“ç§‘ï¼ˆé«˜èŒï¼‰',
        'é«˜èŒ': 'ä¸“ç§‘ï¼ˆé«˜èŒï¼‰',
        'èŒé«˜': 'ä¸“ç§‘ï¼ˆé«˜èŒï¼‰'
    }
    
    for key, value in conversion_map.items():
        if key in level_str:
            return value
    
    return level


def extract_required_subjects_plan(text):
    """æå–å¿…é€‰ç§‘ç›®"""
    if not text:
        return []
    
    text_str = str(text).strip()
    subjects = ['ç‰©', 'åŒ–', 'ç”Ÿ', 'å†', 'åœ°', 'æ”¿', 'æŠ€']
    found_subjects = []
    
    for subject in subjects:
        if subject in text_str:
            found_subjects.append(subject)
    
    return found_subjects


def convert_selection_requirement_plan(group_requirement, major_requirement=''):
    """è½¬æ¢é€‰ç§‘è¦æ±‚"""
    group_req_str = str(group_requirement).strip()
    
    if not group_req_str or group_req_str.lower() == 'nan':
        return 'ä¸é™ç§‘ç›®ä¸“ä¸šç»„'
    
    if 'å¿…é€‰' in group_req_str:
        return 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'
    
    if 'ä¸é™' in group_req_str:
        return 'ä¸é™ç§‘ç›®ä¸“ä¸šç»„'
    
    if 'å¤šé—¨' in group_req_str or 'æˆ–' in group_req_str:
        return 'å¤šé—¨é€‰è€ƒ'
    
    return 'å¤šé—¨é€‰è€ƒ'


def convert_data_to_score_format_plan(unmatched_data, plan_df_original):
    """å°†æœªåŒ¹é…çš„æ‹›ç”Ÿè®¡åˆ’æ•°æ®è½¬æ¢ä¸ºä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿æ ¼å¼"""
    converted_data = []
    
    headers = [
        'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰',
        'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†',
        'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰',
        'æ•°æ®æ¥æº', 'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®',
        'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†æ•°åŒºé—´ä½', 'æœ€ä½åˆ†æ•°åŒºé—´é«˜',
        'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
    ]
    
    for item in unmatched_data:
        try:
            original_index = item['original_index']
            raw_row = plan_df_original.iloc[original_index]
            
            group_req = raw_row.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', '')
            major_req = raw_row.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '')
            
            required_subjects = extract_required_subjects_plan(group_req)
            second_subject = required_subjects[0] if required_subjects else ''
            
            converted_row = {
                'å­¦æ ¡åç§°': raw_row.get('å­¦æ ¡', ''),
                'çœä»½': raw_row.get('çœä»½', ''),
                'æ‹›ç”Ÿä¸“ä¸š': raw_row.get('ä¸“ä¸š', ''),
                'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰': '',
                'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰': raw_row.get('å¤‡æ³¨', ''),
                'ä¸€çº§å±‚æ¬¡': convert_level_plan(raw_row.get('å±‚æ¬¡', '')),
                'æ‹›ç”Ÿç§‘ç±»': raw_row.get('ç§‘ç±»', ''),
                'æ‹›ç”Ÿæ‰¹æ¬¡': raw_row.get('æ‰¹æ¬¡', ''),
                'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰': raw_row.get('æ‹›ç”Ÿç±»å‹', ''),
                'æœ€é«˜åˆ†': '',
                'æœ€ä½åˆ†': '',
                'å¹³å‡åˆ†': '',
                'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': '',
                'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰': raw_row.get('æ‹›ç”Ÿäººæ•°', ''),
                'æ•°æ®æ¥æº': raw_row.get('æ•°æ®æ¥æº', ''),
                'ä¸“ä¸šç»„ä»£ç ': raw_row.get('ä¸“ä¸šç»„ä»£ç ', ''),
                'é¦–é€‰ç§‘ç›®': get_first_subject_plan(raw_row.get('ç§‘ç±»', '')),
                'é€‰ç§‘è¦æ±‚': convert_selection_requirement_plan(group_req, major_req),
                'æ¬¡é€‰ç§‘ç›®': second_subject,
                'ä¸“ä¸šä»£ç ': raw_row.get('ä¸“ä¸šä»£ç ', ''),
                'æ‹›ç”Ÿä»£ç ': raw_row.get('æ‹›ç”Ÿä»£ç ', ''),
                'æœ€ä½åˆ†æ•°åŒºé—´ä½': '',
                'æœ€ä½åˆ†æ•°åŒºé—´é«˜': '',
                'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½': '',
                'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜': '',
                'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰': ''
            }
            
            converted_data.append(converted_row)
        except Exception as e:
            logging.error(f"è½¬æ¢æ•°æ®å¤±è´¥ (ç´¢å¼• {item['original_index']}): {e}")
            continue
    
    return converted_data


# ========== å¯¼å‡ºå‡½æ•° ==========
def export_results_to_excel_plan(results, is_unmatched=False):
    """å¯¼å‡ºæ¯”å¯¹ç»“æœåˆ°Excelæ–‡ä»¶"""
    try:
        if is_unmatched:
            results = [r for r in results if not r['exists']]
        
        data_for_export = []
        for result in results:
            row = {
                'åºå·': result['index'],
                'åŒ¹é…çŠ¶æ€': 'âœ“ åŒ¹é…' if result['exists'] else 'âœ— æœªåŒ¹é…',
                **result['key_fields'],
                **result['other_info']
            }
            data_for_export.append(row)
        
        df = pd.DataFrame(data_for_export)
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='æ¯”å¯¹ç»“æœ', index=False)
            
            workbook = writer.book
            worksheet = writer.sheets['æ¯”å¯¹ç»“æœ']
            
            for column in worksheet.columns:
                max_length = 12
                column_letter = column[0].column_letter
                worksheet.column_dimensions[column_letter].width = max_length
            
            header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')
            header_font = openpyxl.styles.Font(color='FFFFFF', bold=True)
            
            for cell in worksheet[1]:
                cell.fill = header_fill
                cell.font = header_font
                cell.alignment = Alignment(horizontal='center', vertical='center')
        
        output.seek(0)
        return output.getvalue()
    
    except Exception as e:
        logging.error(f"å¯¼å‡ºå¤±è´¥: {e}")
        raise


def export_converted_data_to_excel_plan(converted_data, admission_year=''):
    """å¯¼å‡ºè½¬æ¢åçš„æ•°æ®ä¸ºä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿æ ¼å¼"""
    try:
        from openpyxl import Workbook
        
        wb = Workbook()
        ws = wb.active
        ws.title = 'ä¸“ä¸šåˆ†æ•°æ®'
        
        remark_text = (
            "1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰ "
            "2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š\"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»\"ï¼Œå†…è’™å¤é™å®š\"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²\"ï¼Œå…¶ä»–çœä»½é™å®š\"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†\" "
            "3.æ‰¹æ¬¡ï¼šæ²³åŒ—ã€å†…è’™å¤ç­‰çœä»½é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ç­‰ã€‚è¯¦è§è¯´æ˜ã€‚ "
            "4.æ‹›ç”Ÿäººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­— "
            "5.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼Œä¿ç•™å°æ•°åä¸¤ä½ "
            "6.ä¸€çº§å±‚æ¬¡ï¼šé™å®š\"æœ¬ç§‘ã€ä¸“ç§‘ï¼ˆé«˜èŒï¼‰\" "
            "7.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­— "
            "8.æ•°æ®æ¥æºï¼šå¿…é¡»é™å®šâ€”â€”å®˜æ–¹è€ƒè¯•é™¢ã€å¤§çº¢æœ¬æ•°æ®ã€å­¦æ ¡å®˜ç½‘ã€é”€å”®ã€æŠ“å–ã€åœ£è¾¾ä¿¡ã€ä¼˜å¿—æ„¿ã€å­¦ä¸šæ¡¥ "
            "9.é€‰ç§‘è¦æ±‚ï¼šä¸é™ç§‘ç›®ä¸“ä¸šç»„;å¤šé—¨é€‰è€ƒ;å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ "
            "10.é€‰ç§‘ç§‘ç›®å¿…é¡»æ˜¯ç§‘ç›®çš„ç®€å†™ï¼ˆç‰©ã€åŒ–ã€ç”Ÿã€å†ã€åœ°ã€æ”¿ã€æŠ€ï¼‰"
        )
        
        ws.append([remark_text])
        ws.append(['æ‹›ç”Ÿå¹´ä»½', admission_year])
        
        headers = [
            'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰',
            'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†',
            'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰',
            'æ•°æ®æ¥æº', 'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®',
            'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†æ•°åŒºé—´ä½', 'æœ€ä½åˆ†æ•°åŒºé—´é«˜',
            'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
        ]
        ws.append(headers)
        
        for row_data in converted_data:
            row_values = [row_data.get(header, '') for header in headers]
            ws.append(row_values)
        
        ws.merge_cells('A1:Y1')
        ws['A1'].alignment = Alignment(wrap_text=True, vertical='top', horizontal='left')
        ws.row_dimensions[1].height = 100
        
        for col_idx, header in enumerate(headers, start=1):
            ws.column_dimensions[get_column_letter(col_idx)].width = 12
        
        header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')
        header_font = openpyxl.styles.Font(color='FFFFFF', bold=True)
        
        for cell in ws[3]:
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
        
        output = BytesIO()
        wb.save(output)
        output.seek(0)
        
        return output.getvalue()
    
    except Exception as e:
        logging.error(f"è½¬æ¢å¯¼å‡ºå¤±è´¥: {e}")
        raise


# ====================== æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ ======================

with tab7:
    st.header("ğŸ“ æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ä¸è½¬æ¢å·¥å…·")
    st.markdown("""
    ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’ã€ä¸“ä¸šåˆ†å’Œé™¢æ ¡åˆ†æ–‡ä»¶è¿›è¡Œæ¯”å¯¹ï¼Œå¿«é€Ÿå®šä½æœªåŒ¹é…æ•°æ®ï¼Œ
    å¹¶å¯è‡ªåŠ¨è½¬æ¢ä¸ºä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿æ ¼å¼ã€‚
    """)
    
    # è¯´æ˜
    with st.expander("ğŸ“ ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        **å·¥ä½œæµç¨‹ï¼š**
        1. **ä¸Šä¼ æ–‡ä»¶** - ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’ã€ä¸“ä¸šåˆ†å’Œé™¢æ ¡åˆ†æ–‡ä»¶
        2. **æ•°æ®æ¯”å¯¹** - æ‰§è¡Œæ¯”å¯¹1ã€æ¯”å¯¹2æˆ–å…¨éƒ¨æ¯”å¯¹
        3. **ç»“æœæ£€æŸ¥** - æŸ¥çœ‹åŒ¹é…æƒ…å†µï¼Œè¿‡æ»¤å’Œå¯¼å‡ºç»“æœ
        4. **æ•°æ®è½¬æ¢** - å°†æœªåŒ¹é…æ•°æ®è½¬æ¢ä¸ºä¸“ä¸šåˆ†æ ¼å¼
        
        **æ¯”å¯¹å­—æ®µè¯´æ˜ï¼š**
        - **æ¯”å¯¹1** (æ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†)ï¼šå¹´ä»½ã€çœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€ä¸“ä¸šã€å±‚æ¬¡ã€ä¸“ä¸šç»„ä»£ç 
        - **æ¯”å¯¹2** (æ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†)ï¼šå¹´ä»½ã€çœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€ä¸“ä¸šç»„ä»£ç 
        """)
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'plan_df_tab7' not in st.session_state:
        st.session_state.plan_df_tab7 = None
    if 'score_df_tab7' not in st.session_state:
        st.session_state.score_df_tab7 = None
    if 'college_df_tab7' not in st.session_state:
        st.session_state.college_df_tab7 = None
    if 'plan_score_results_tab7' not in st.session_state:
        st.session_state.plan_score_results_tab7 = None
    if 'plan_college_results_tab7' not in st.session_state:
        st.session_state.plan_college_results_tab7 = None
    if 'converted_data_tab7' not in st.session_state:
        st.session_state.converted_data_tab7 = None
    if 'conversion_source_tab7' not in st.session_state:
        st.session_state.conversion_source_tab7 = None
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.subheader("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶**")
        plan_file = st.file_uploader("é€‰æ‹©æ‹›ç”Ÿè®¡åˆ’Excelæ–‡ä»¶", type=["xlsx", "xls"], key="plan_file_tab7")
        if plan_file:
            try:
                st.session_state.plan_df_tab7 = load_excel_from_bytes_plan(plan_file.getvalue())
                st.success(f"âœ“ å·²åŠ è½½ {len(st.session_state.plan_df_tab7)} æ¡è®°å½•")
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {str(e)}")
    
    with col2:
        st.write("**ä¸“ä¸šåˆ†æ–‡ä»¶**")
        score_file = st.file_uploader("é€‰æ‹©ä¸“ä¸šåˆ†Excelæ–‡ä»¶", type=["xlsx", "xls"], key="score_file_tab7")
        if score_file:
            try:
                st.session_state.score_df_tab7 = load_excel_from_bytes_plan(score_file.getvalue())
                st.success(f"âœ“ å·²åŠ è½½ {len(st.session_state.score_df_tab7)} æ¡è®°å½•")
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {str(e)}")
    
    with col3:
        st.write("**é™¢æ ¡åˆ†æ–‡ä»¶**")
        college_file = st.file_uploader("é€‰æ‹©é™¢æ ¡åˆ†Excelæ–‡ä»¶", type=["xlsx", "xls"], key="college_file_tab7")
        if college_file:
            try:
                st.session_state.college_df_tab7 = load_excel_from_bytes_plan(college_file.getvalue())
                st.success(f"âœ“ å·²åŠ è½½ {len(st.session_state.college_df_tab7)} æ¡è®°å½•")
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {str(e)}")
    
    st.divider()
    
    # æ¯”å¯¹æ“ä½œ
    st.subheader("ğŸ” æ•°æ®æ¯”å¯¹")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†", key="compare_plan_score_tab7"):
            if st.session_state.plan_df_tab7 is None:
                st.error("è¯·å…ˆä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
            elif st.session_state.score_df_tab7 is None:
                st.error("è¯·å…ˆä¸Šä¼ ä¸“ä¸šåˆ†æ–‡ä»¶")
            else:
                with st.spinner("æ­£åœ¨è¿›è¡Œæ¯”å¯¹1..."):
                    try:
                        st.session_state.plan_score_results_tab7 = compare_plan_vs_score_func(
                            st.session_state.plan_df_tab7,
                            st.session_state.score_df_tab7
                        )
                        st.success("âœ“ æ¯”å¯¹1å®Œæˆ")
                        st.session_state.conversion_source_tab7 = 'planScore'
                    except Exception as e:
                        st.error(f"æ¯”å¯¹å¤±è´¥: {str(e)}")
    
    with col2:
        if st.button("æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†", key="compare_plan_college_tab7"):
            if st.session_state.plan_df_tab7 is None:
                st.error("è¯·å…ˆä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
            elif st.session_state.college_df_tab7 is None:
                st.error("è¯·å…ˆä¸Šä¼ é™¢æ ¡åˆ†æ–‡ä»¶")
            else:
                with st.spinner("æ­£åœ¨è¿›è¡Œæ¯”å¯¹2..."):
                    try:
                        st.session_state.plan_college_results_tab7 = compare_plan_vs_college_func(
                            st.session_state.plan_df_tab7,
                            st.session_state.college_df_tab7
                        )
                        st.success("âœ“ æ¯”å¯¹2å®Œæˆ")
                        st.session_state.conversion_source_tab7 = 'planCollege'
                    except Exception as e:
                        st.error(f"æ¯”å¯¹å¤±è´¥: {str(e)}")
    
    with col3:
        if st.button("å…¨éƒ¨æ¯”å¯¹", key="compare_all_tab7"):
            has_plan = st.session_state.plan_df_tab7 is not None
            has_score = st.session_state.score_df_tab7 is not None
            has_college = st.session_state.college_df_tab7 is not None
            
            if not has_plan:
                st.error("è¯·å…ˆä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
            elif not (has_score or has_college):
                st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸“ä¸šåˆ†æˆ–é™¢æ ¡åˆ†æ–‡ä»¶")
            else:
                with st.spinner("æ­£åœ¨æ‰§è¡Œå…¨éƒ¨æ¯”å¯¹..."):
                    try:
                        if has_score:
                            st.session_state.plan_score_results_tab7 = compare_plan_vs_score_func(
                                st.session_state.plan_df_tab7,
                                st.session_state.score_df_tab7
                            )
                        if has_college:
                            st.session_state.plan_college_results_tab7 = compare_plan_vs_college_func(
                                st.session_state.plan_df_tab7,
                                st.session_state.college_df_tab7
                            )
                        st.success("âœ“ å…¨éƒ¨æ¯”å¯¹å®Œæˆ")
                    except Exception as e:
                        st.error(f"æ¯”å¯¹å¤±è´¥: {str(e)}")
    
    with col4:
        if st.button("é‡ç½®æ‰€æœ‰æ•°æ®", key="reset_all_tab7"):
            st.session_state.plan_df_tab7 = None
            st.session_state.score_df_tab7 = None
            st.session_state.college_df_tab7 = None
            st.session_state.plan_score_results_tab7 = None
            st.session_state.plan_college_results_tab7 = None
            st.session_state.converted_data_tab7 = None
            st.session_state.conversion_source_tab7 = None
            st.success("âœ“ å·²é‡ç½®æ‰€æœ‰æ•°æ®")
    
    st.divider()
    
    # æ˜¾ç¤ºæ¯”å¯¹1ç»“æœ
    if st.session_state.plan_score_results_tab7:
        st.subheader("ğŸ“Š æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†")
        
        results = st.session_state.plan_score_results_tab7
        stats = get_comparison_stats_plan(results)
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("æ€»è®°å½•æ•°", stats['total'])
        col2.metric("åŒ¹é…è®°å½•æ•°", stats['matched'], delta="âœ“")
        col3.metric("æœªåŒ¹é…è®°å½•æ•°", stats['unmatched'], delta="âœ—")
        col4.metric("åŒ¹é…ç‡", stats['match_rate'])
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            provinces = ['å…¨éƒ¨'] + get_unique_provinces_plan(results)
            selected_province = st.selectbox(
                "æŒ‰çœä»½ç­›é€‰",
                provinces,
                key="plan_score_province_tab7"
            )
        
        with col2:
            batches = ['å…¨éƒ¨'] + get_unique_batches_plan(results)
            selected_batch = st.selectbox(
                "æŒ‰æ‰¹æ¬¡ç­›é€‰",
                batches,
                key="plan_score_batch_tab7"
            )
        
        with col3:
            match_status = st.selectbox(
                "åŒ¹é…çŠ¶æ€",
                ['å…¨éƒ¨', 'åŒ¹é…', 'æœªåŒ¹é…'],
                key="plan_score_status_tab7"
            )
        
        filtered_results = results
        
        if selected_province != 'å…¨éƒ¨':
            filtered_results = [r for r in filtered_results 
                               if str(r['key_fields']['çœä»½']).strip() == selected_province]
        
        if selected_batch != 'å…¨éƒ¨':
            filtered_results = [r for r in filtered_results 
                               if str(r['key_fields']['æ‰¹æ¬¡']).strip() == selected_batch]
        
        if match_status == 'åŒ¹é…':
            filtered_results = [r for r in filtered_results if r['exists']]
        elif match_status == 'æœªåŒ¹é…':
            filtered_results = [r for r in filtered_results if not r['exists']]
        
        st.write(f"**æ˜¾ç¤º {len(filtered_results)} æ¡è®°å½•**")
        
        display_data = []
        for result in filtered_results[:500]:
            row = {
                'åºå·': result['index'],
                'çŠ¶æ€': 'âœ“ åŒ¹é…' if result['exists'] else 'âœ— æœªåŒ¹é…',
                **result['key_fields']
            }
            display_data.append(row)
        
        st.dataframe(pd.DataFrame(display_data), use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“¥ å¯¼å‡ºæ¯”å¯¹ç»“æœ", key="export_plan_score_results_tab7"):
                try:
                    file_bytes = export_results_to_excel_plan(results, False)
                    st.download_button(
                        label="ä¸‹è½½ æ¯”å¯¹1 ç»“æœ",
                        data=file_bytes,
                        file_name="æ‹›ç”Ÿè®¡åˆ’vsä¸“ä¸šåˆ†_æ¯”å¯¹ç»“æœ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        
        with col2:
            if st.button("ğŸ”„ è½¬æ¢æœªåŒ¹é…æ•°æ®ä¸ºä¸“ä¸šåˆ†æ ¼å¼", key="convert_plan_score_tab7"):
                unmatched = [r for r in results if not r['exists']]
                if not unmatched:
                    st.warning("æ²¡æœ‰æœªåŒ¹é…çš„æ•°æ®")
                else:
                    try:
                        converted = convert_data_to_score_format_plan(unmatched, st.session_state.plan_df_tab7)
                        st.session_state.converted_data_tab7 = converted
                        st.session_state.conversion_source_tab7 = 'planScore'
                        st.success(f"âœ“ å·²è½¬æ¢ {len(converted)} æ¡æœªåŒ¹é…æ•°æ®")
                    except Exception as e:
                        st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
        
        st.divider()
    
    # æ˜¾ç¤ºæ¯”å¯¹2ç»“æœ
    if st.session_state.plan_college_results_tab7:
        st.subheader("ğŸ“Š æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†")
        
        results = st.session_state.plan_college_results_tab7
        stats = get_comparison_stats_plan(results)
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("æ€»è®°å½•æ•°", stats['total'])
        col2.metric("åŒ¹é…è®°å½•æ•°", stats['matched'], delta="âœ“")
        col3.metric("æœªåŒ¹é…è®°å½•æ•°", stats['unmatched'], delta="âœ—")
        col4.metric("åŒ¹é…ç‡", stats['match_rate'])
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            provinces = ['å…¨éƒ¨'] + get_unique_provinces_plan(results)
            selected_province = st.selectbox(
                "æŒ‰çœä»½ç­›é€‰",
                provinces,
                key="plan_college_province_tab7"
            )
        
        with col2:
            batches = ['å…¨éƒ¨'] + get_unique_batches_plan(results)
            selected_batch = st.selectbox(
                "æŒ‰æ‰¹æ¬¡ç­›é€‰",
                batches,
                key="plan_college_batch_tab7"
            )
        
        with col3:
            match_status = st.selectbox(
                "åŒ¹é…çŠ¶æ€",
                ['å…¨éƒ¨', 'åŒ¹é…', 'æœªåŒ¹é…'],
                key="plan_college_status_tab7"
            )
        
        filtered_results = results
        
        if selected_province != 'å…¨éƒ¨':
            filtered_results = [r for r in filtered_results 
                               if str(r['key_fields']['çœä»½']).strip() == selected_province]
        
        if selected_batch != 'å…¨éƒ¨':
            filtered_results = [r for r in filtered_results 
                               if str(r['key_fields']['æ‰¹æ¬¡']).strip() == selected_batch]
        
        if match_status == 'åŒ¹é…':
            filtered_results = [r for r in filtered_results if r['exists']]
        elif match_status == 'æœªåŒ¹é…':
            filtered_results = [r for r in filtered_results if not r['exists']]
        
        st.write(f"**æ˜¾ç¤º {len(filtered_results)} æ¡è®°å½•**")
        
        display_data = []
        for result in filtered_results[:500]:
            row = {
                'åºå·': result['index'],
                'çŠ¶æ€': 'âœ“ åŒ¹é…' if result['exists'] else 'âœ— æœªåŒ¹é…',
                **result['key_fields']
            }
            display_data.append(row)
        
        st.dataframe(pd.DataFrame(display_data), use_container_width=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“¥ å¯¼å‡ºæ¯”å¯¹ç»“æœ", key="export_plan_college_results_tab7"):
                try:
                    file_bytes = export_results_to_excel_plan(results, False)
                    st.download_button(
                        label="ä¸‹è½½ æ¯”å¯¹2 ç»“æœ",
                        data=file_bytes,
                        file_name="æ‹›ç”Ÿè®¡åˆ’vsé™¢æ ¡åˆ†_æ¯”å¯¹ç»“æœ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        
        with col2:
            if st.button("ğŸ”„ è½¬æ¢æœªåŒ¹é…æ•°æ®ä¸ºä¸“ä¸šåˆ†æ ¼å¼", key="convert_plan_college_tab7"):
                unmatched = [r for r in results if not r['exists']]
                if not unmatched:
                    st.warning("æ²¡æœ‰æœªåŒ¹é…çš„æ•°æ®")
                else:
                    try:
                        converted = convert_data_to_score_format_plan(unmatched, st.session_state.plan_df_tab7)
                        st.session_state.converted_data_tab7 = converted
                        st.session_state.conversion_source_tab7 = 'planCollege'
                        st.success(f"âœ“ å·²è½¬æ¢ {len(converted)} æ¡æœªåŒ¹é…æ•°æ®")
                    except Exception as e:
                        st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
        
        st.divider()
    
    # è½¬æ¢å¯¼å‡ºéƒ¨åˆ†
    if st.session_state.converted_data_tab7:
        st.subheader("ğŸ¯ æœªåŒ¹é…æ•°æ®è½¬æ¢")
        
        converted_data = st.session_state.converted_data_tab7
        source = st.session_state.conversion_source_tab7
        
        col1, col2, col3 = st.columns(3)
        col1.metric("å¾…è½¬æ¢è®°å½•æ•°", len(converted_data))
        col2.metric("è½¬æ¢æ¥æº", 'æ¯”å¯¹1' if source == 'planScore' else 'æ¯”å¯¹2')
        
        st.write("**é¢„è§ˆå‰10æ¡è½¬æ¢ç»“æœï¼š**")
        preview_df = pd.DataFrame(converted_data[:10])
        st.dataframe(preview_df, use_container_width=True)
        
        if st.button("ğŸ’¾ å¯¼å‡ºä¸ºä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿æ ¼å¼", key="export_converted_tab7"):
            try:
                admission_year = ''
                if st.session_state.plan_df_tab7 is not None and 'å¹´ä»½' in st.session_state.plan_df_tab7.columns:
                    admission_year = str(st.session_state.plan_df_tab7['å¹´ä»½'].iloc[0])
                
                file_bytes = export_converted_data_to_excel_plan(converted_data, admission_year)
                st.download_button(
                    label="ä¸‹è½½ æœªåŒ¹é…æ•°æ®ï¼ˆä¸“ä¸šåˆ†æ ¼å¼ï¼‰",
                    data=file_bytes,
                    file_name="æœªåŒ¹é…æ•°æ®_ä¸“ä¸šåˆ†æ ¼å¼.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                st.success("âœ“ å·²ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶")
            except Exception as e:
                st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")


# é¡µè„š
st.markdown("---")
st.markdown("Â© æ•°æ®å¤„ç†", unsafe_allow_html=True)